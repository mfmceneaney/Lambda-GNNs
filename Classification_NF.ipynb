{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3423440-b266-4372-b031-e048056cc712",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/group/vossenlab/rck32/miniconda3/envs/venv/lib/python3.11/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/hpc/group/vossenlab/rck32/miniconda3/envs/venv/lib/python3.11/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/hpc/group/vossenlab/rck32/miniconda3/envs/venv/lib/python3.11/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/hpc/group/vossenlab/rck32/miniconda3/envs/venv/lib/python3.11/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "2023-06-28 14:49:13.785358: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-28 14:49:18.172088: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import normflows as nf\n",
    "from normflows import flows\n",
    "## Standard libraries\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as tdata\n",
    "import torch.optim as optim\n",
    "\n",
    "import dgl #NOTE: for dgl.batch and dgl.unbatch\n",
    "from dgl import save_graphs, load_graphs\n",
    "from dgl.data import DGLDataset\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from dgl.data.utils import save_info, load_info, Subset\n",
    "\n",
    "import umap\n",
    "reducer = umap.UMAP();\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Fetching the device that will be used throughout this notebook\n",
    "device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda:0\")\n",
    "print(\"Using device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c4c7f45-97b3-4cfb-a6b5-d917770f97d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "#custom imports\n",
    "from utils import load_graph_dataset, train, evaluate, GraphDataset, get_graph_dataset_info\n",
    "from models import GIN, HeteroGIN\n",
    "# from NF_utils import Latent_data, get_masked_affine, transform, train,plot_loss, test,plot_9_histos, plot_UMAP_sidebyside,plot_UMAP_overlay, create_latent_data\n",
    "from NF_utils import Latent_data, transform,plot_loss, test,plot_9_histos, plot_UMAP_sidebyside,plot_UMAP_overlay, create_latent_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9de4853-6f7b-4236-934b-ba37c9fe20e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''                                              '''\n",
    "'''     SETTING UP LATENT SPACE REPRESENTATION   '''\n",
    "'''                                              '''\n",
    "\n",
    "# Data and MC both have the same prefix\n",
    "prefix = \"/hpc/group/vossenlab/mfm45/.dgl/\"\n",
    "\n",
    "# MC inside Lambda_train_matched_jobs_outbending_cache_bg50nA_7_28_22__pT_phi_theta_beta_chi2_pid_status__Normalized\n",
    "MCdataset = \"Lambda_train_matched_jobs_outbending_cache_bg50nA_7_28_22__pT_phi_theta_beta_chi2_pid_status__Normalized\"\n",
    "\n",
    "# Data inside data_jobs_rga_fall2018_7_28_22__pT_phi_theta_beta_chi2_pid_status__Normalized\n",
    "DATAdataset = \"data_jobs_rga_fall2018_7_28_22__pT_phi_theta_beta_chi2_pid_status__Normalized\"\n",
    "\n",
    "max_events = 1e5\n",
    "split = 0.1\n",
    "nlayers = 2\n",
    "nmlp = 3\n",
    "hdim = 64\n",
    "nclasses, nfeatures, nfeatures_edge = get_graph_dataset_info(dataset=MCdataset, prefix=prefix)\n",
    "dropout = 0.8\n",
    "learn_eps = False\n",
    "batch = 256\n",
    "indices = None\n",
    "nworkers = 0\n",
    "npooling = \"max\"\n",
    "gpooling = \"max\"\n",
    "torch.manual_seed(0)\n",
    "\n",
    "#select model\n",
    "extractor = GIN(nlayers, nmlp, nfeatures,\n",
    "            hdim, nclasses, dropout, learn_eps, npooling, gpooling).to(device)\n",
    "extractor.load_state_dict(torch.load(\"logs/model_weights\",map_location=device))\n",
    "#select training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ade36de-98ea-48e7-8ca1-a8e60ffffd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No mode given, defaulting to training\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data_DATA = create_latent_data(DATAdataset, extractor,num_samples = 100)\n",
    "training_data_MC = create_latent_data(MCdataset, extractor,num_samples = 100)\n",
    "\n",
    "testing_data_DATA = create_latent_data(DATAdataset, extractor, mode = \"test\",num_samples = 100)\n",
    "testing_data_MC = create_latent_data(MCdataset, extractor, mode = \"test\",num_samples = 100)\n",
    "\n",
    "val_data_DATA = create_latent_data(DATAdataset, extractor, mode = \"val\",num_samples = 100)\n",
    "val_data_MC = create_latent_data(MCdataset, extractor, mode = \"val\",num_samples = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60808554-f05b-4dbb-b5b7-d082e4ec4740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(in_data, model, val = False,val_data = Latent_data(torch.empty(10000,71), torch.empty(10000,71)), num_epochs = 1, compact_num = 20):\n",
    "    # train the MC model\n",
    "    if(val):\n",
    "        val_data.set_batch_size(int(np.floor(val_data.num_events / in_data.max_iter)))\n",
    "        val_loss_hist = np.array([])\n",
    "        full_val_loss_hist = np.array([])\n",
    "    model.train()\n",
    "    loss_hist = np.array([])\n",
    "    full_loss_hist = np.array([])\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-5)\n",
    "    for i in range(num_epochs):\n",
    "        with tqdm(total=in_data.max_iter, position=0, leave=True) as pbar:\n",
    "            for it in tqdm(range(in_data.max_iter), position = 0, leave=True):\n",
    "                optimizer.zero_grad()\n",
    "                #randomly sample the latent space\n",
    "                samples = in_data.sample(iteration = it)\n",
    "                samples = samples.to(device)\n",
    "                loss = model.forward_kld(samples)\n",
    "                # Do backprop and optimizer step\n",
    "                if ~(torch.isnan(loss) | torch.isinf(loss)):\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                # Log loss\n",
    "                if~(torch.isnan(loss)):\n",
    "                    full_loss_hist = np.append(loss_hist, loss.to('cpu').data.numpy())\n",
    "                    if(loss < 1000):\n",
    "                        loss_hist = np.append(loss_hist, loss.to('cpu').data.numpy())\n",
    "                if(val):\n",
    "                    val_samples = val_data.sample(iteration = it)\n",
    "                    val_samples = val_samples.to(device)\n",
    "                    val_loss = model.forward_kld(val_samples)\n",
    "                    if~(torch.isnan(val_loss)):\n",
    "                        full_val_loss_hist = np.append(val_loss_hist, val_loss.to('cpu').data.numpy())\n",
    "                        if(val_loss < 1000):\n",
    "                            val_loss_hist = np.append(val_loss_hist, val_loss.to('cpu').data.numpy())\n",
    "    running_ttl = 0\n",
    "    compact_hist = np.array([])\n",
    "    j = 0\n",
    "    for i in range(loss_hist.size):\n",
    "        if(j != (i // compact_num)):\n",
    "            compact_hist = np.append(compact_hist,running_ttl / compact_num)\n",
    "            running_ttl = 0\n",
    "        j = i // compact_num\n",
    "        running_ttl += loss_hist[i]\n",
    "    if(val):\n",
    "        running_ttl_val = 0\n",
    "        compact_hist_val = np.array([])\n",
    "        j = 0\n",
    "        for i in range(val_loss_hist.size):\n",
    "            if(j != (i // compact_num)):\n",
    "                compact_hist_val = np.append(compact_hist_val,running_ttl_val / compact_num)\n",
    "                running_ttl_val = 0\n",
    "            j = i // compact_num\n",
    "            running_ttl_val += val_loss_hist[i]\n",
    "        return compact_hist, compact_hist_val, full_loss_hist, full_val_loss_hist\n",
    "    else:\n",
    "        return compact_hist, loss_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22695cfb-dc5b-4d4e-afa6-6e6978439d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_masked_affine(num_layers = 32):\n",
    "    #mask\n",
    "    b = torch.ones(71)\n",
    "    for i in range(b.size()[0]):\n",
    "        if i % 2 == 0:\n",
    "            b[i] = 0\n",
    "    masked_affine_flows = []\n",
    "    for i in range(num_layers):\n",
    "        s = nf.nets.MLP([71, 142, 142, 71])\n",
    "        t = nf.nets.MLP([71, 142, 142, 71])\n",
    "        if i % 2 == 0:\n",
    "            masked_affine_flows += [nf.flows.MaskedAffineFlow(b, t, s)]\n",
    "        else:\n",
    "            masked_affine_flows += [nf.flows.MaskedAffineFlow(1 - b, t, s)]\n",
    "    return masked_affine_flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985cd965-dcba-4e55-b37e-728155876507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTING UP DATA MODEL\n",
    "\n",
    "masked_affine_flows_train_DATA = get_masked_affine(48)\n",
    "distribution_DATA = nf.distributions.DiagGaussian(training_data_DATA.latent_size, trainable = False)\n",
    "masked_affine_model_DATA = nf.NormalizingFlow(q0=distribution_DATA, flows=masked_affine_flows_train_DATA)\n",
    "DATA_model = masked_affine_model_DATA.to(device)\n",
    "\n",
    "# SETTING UP MC MODEL\n",
    "\n",
    "masked_affine_flows_train_MC = get_masked_affine(48)\n",
    "distribution_MC = nf.distributions.DiagGaussian(training_data_MC.latent_size, trainable = False)\n",
    "masked_affine_model_MC = nf.NormalizingFlow(q0=distribution_MC, flows=masked_affine_flows_train_MC)\n",
    "MC_model = masked_affine_model_MC.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e270e1e4-478d-4a9e-b46d-41d4b470f296",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 58/1120 [00:06<01:57,  9.03it/s]"
     ]
    }
   ],
   "source": [
    "# TRAINING MC\n",
    "loss_hist, val_hist, full_loss_hist, full_val_hist = train(training_data_MC, MC_model, val = True, val_data = val_data_MC, num_epochs = 2, compact_num = 20)\n",
    "plot_loss(loss_hist, label = \"MC loss\",plot_val = True, val_loss_hist = val_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe296596-06aa-4c75-b83b-5b4de484d5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING DATA\n",
    "loss_hist, val_hist, full_loss_hist, full_val_hist = train(training_data_DATA, DATA_model, val = True, val_data = val_data_DATA, num_epochs = 2, compact_num = 20)\n",
    "plot_loss(loss_hist, label = \"DATA loss\", plot_val = True, val_loss_hist = val_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798ec245-fd43-4feb-88b1-ba11f9226494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing MC\n",
    "test(testing_data_MC, MC_model, data_type = \"MC\")\n",
    "# Testing DATA\n",
    "test(testing_data_DATA, DATA_model, data_type = \"DATA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf7c202-e791-4a26-9964-c2196f1a6951",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_latent_MC = transform(testing_data_MC, MC_model)\n",
    "transformed_latent_DATA = transform(testing_data_DATA, DATA_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a980dc-1d2b-47d8-8423-28839cb26404",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_latent_train_MC = transform(training_data_MC, MC_model)\n",
    "transformed_latent_train_DATA = transform(training_data_DATA, DATA_model)\n",
    "transformed_latent_val_MC = transform(val_data_MC, MC_model)\n",
    "transformed_latent_val_DATA = transform(val_data_DATA, DATA_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead1efa8-deba-48d7-867f-8c82d3fcc8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From above plotting: <transformed_latent_DATA> is the tensor with normalized DATA\n",
    "# Now need to transform it back to MC version of latent space\n",
    "transformed_latent_DATA_obj = Latent_data(transformed_latent_DATA,testing_data_DATA.labels)\n",
    "transformed_latent_DATA_obj.set_batch_size(100)\n",
    "transformed_latent_MC_obj = Latent_data(transformed_latent_MC,testing_data_MC.labels)\n",
    "transformed_latent_MC_obj.set_batch_size(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29729091-0c85-46bc-a4a2-2ffc45c32e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_latent_train_DATA_obj = Latent_data(transformed_latent_train_DATA,training_data_DATA.labels)\n",
    "transformed_latent_train_DATA_obj.set_batch_size(100)\n",
    "transformed_latent_train_MC_obj = Latent_data(transformed_latent_train_MC,training_data_MC.labels)\n",
    "transformed_latent_train_MC_obj.set_batch_size(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ceca85a-1ffe-4b4f-a340-f916d009b085",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_latent_val_DATA_obj = Latent_data(transformed_latent_val_DATA,val_data_DATA.labels)\n",
    "transformed_latent_val_MC_obj = Latent_data(transformed_latent_val_MC,val_data_MC.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940369f3-032b-41a5-9388-173deb56a29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pass_DATA = transform(transformed_latent_DATA_obj, MC_model, reverse = False)\n",
    "full_pass_DATA_obj = Latent_data(full_pass_DATA, testing_data_DATA.labels)\n",
    "full_pass_DATA_obj.set_batch_size(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736e60a8-a31c-4ab8-ba68-cc8e52e9ec85",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc9fb4d-fd8d-4210-ad28-31f4833c2ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NFClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Classifier for normalized tensors\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=71, num_classes=2, hidden_dim = 256, num_layers = 5):\n",
    "        super(NFClassifier, self).__init__()\n",
    "        self.layer = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            if(i == 0):\n",
    "                self.layer.append(\n",
    "                nn.Linear(input_size, hidden_dim)\n",
    "                )\n",
    "                self.layer.append(\n",
    "                    nn.ReLU(inplace=True)\n",
    "                )\n",
    "            elif(i == num_layers - 1):\n",
    "                self.layer.append(\n",
    "                nn.Linear(hidden_dim, num_classes)\n",
    "                )\n",
    "            else:\n",
    "                self.layer.append(\n",
    "                    nn.Linear(hidden_dim, hidden_dim)\n",
    "                )\n",
    "                self.layer.append(\n",
    "                    nn.ReLU(inplace=True)\n",
    "                )\n",
    "        self.name = \"Classifier\"\n",
    "        \n",
    "    def forward(self, h):\n",
    "        c = self.layer(h)\n",
    "        return c\n",
    "    \n",
    "    # @property\n",
    "    def name(self):\n",
    "        \"\"\"\n",
    "        Name of model.\n",
    "        \"\"\"\n",
    "        return self.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc2b254-c509-4e90-b54b-c04e5f356f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = NFClassifier().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeca52c0-bdd8-4553-97ff-e45306d01fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=5e-4, weight_decay=1e-5)\n",
    "num_epochs = 6\n",
    "def train_classifier(train_data, classifier, criterion, optimizer, val = True, val_data = val_data, num_epochs = 1):\n",
    "    loss_hist = np.array([])\n",
    "    if(val):\n",
    "        val_data.set_batch_size(int(np.floor(val_data.num_events / train_data.max_iter)))\n",
    "        val_loss_hist = np.array([])\n",
    "    for i in range(num_epochs):\n",
    "        epoch_hist = np.array([])\n",
    "        val_epoch_hist = np.array([])\n",
    "        with tqdm(total=train_data.max_iter, position=0, leave=True) as pbar:\n",
    "            for it in tqdm(range(train_data.max_iter), position = 0, leave=True):\n",
    "                optimizer.zero_grad()\n",
    "                #randomly sample the latent space\n",
    "                samples, labels = train_data.sample(iteration = it, _give_labels = True)\n",
    "                samples = samples.to(device)\n",
    "                labels = (labels.type(torch.LongTensor)).to(device)\n",
    "                # forward + backward + optimize\n",
    "                outputs = classifier(samples)\n",
    "                loss = criterion(outputs, labels[:,0])\n",
    "                # Do backprop and optimizer step\n",
    "                if ~(torch.isnan(loss) | torch.isinf(loss)):\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                # Log loss\n",
    "                if~(torch.isnan(loss)):\n",
    "                    epoch_hist = np.append(epoch_hist, loss.to('cpu').data.numpy())\n",
    "                if(val):\n",
    "                    #validation\n",
    "                    val_samples, val_labels = val_data.sample(iteration = it, _give_labels = True)\n",
    "                    val_samples = val_samples.to(device)\n",
    "                    val_labels = (val_labels.type(torch.LongTensor)).to(device)\n",
    "                    val_outputs = classifier(val_samples)\n",
    "                    val_loss = criterion(val_outputs, val_labels[:,0])\n",
    "                    val_epoch_hist = np.append(val_epoch_hist, val_loss.to('cpu').data.numpy())\n",
    "        loss_hist = np.append(loss_hist, epoch_hist.mean())\n",
    "        if(val):\n",
    "            val_loss_hist = np.append(val_loss_hist, val_epoch_hist.mean())\n",
    "\n",
    "    print('Finished Training')\n",
    "    if(val):\n",
    "        return loss_hist, val_loss_hist\n",
    "    else:\n",
    "        return loss_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c52f07-7399-4936-bbbd-0f98b9f0657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_hist, val_loss_hist = train_classifier(train_data, classifier, criterion, optimizer, val = True, val_data = val_data, num_epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c54335a-bc88-45a6-8dd4-50dc88a5ad89",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(loss_hist, plot_val =True, val_loss_hist = val_loss_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c933e4a-1bf4-467c-84b0-eef4244a3c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = torch.empty(testing_data_MC.num_events,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c34115d-a979-4a15-a412-8e5eeee4f5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "def test_classifier_MC(test_data, classifier):\n",
    "    outputs = torch.empty(test_data.num_events,2)    \n",
    "    with tqdm(total=test_data.max_iter, position=0, leave=True) as pbar:\n",
    "        for it in tqdm(range(test_data.max_iter), position = 0, leave=True):\n",
    "            #randomly sample the latent space\n",
    "            samples, labels = test_data.sample(iteration = it, _give_labels = True)\n",
    "            samples = samples.to(device)\n",
    "            # forward + backward + optimize\n",
    "            output_batch = classifier(samples)\n",
    "            for i in range(test_data.batch_size):\n",
    "                outputs[it*test_data.batch_size + i] = output_batch[i]\n",
    "    test_Y     = test_data.labels.clone().detach().float().view(-1, 1).to(\"cpu\")\n",
    "    probs_Y = torch.softmax(outputs, 1)\n",
    "    argmax_Y = torch.max(probs_Y, 1)[1].view(-1,1)\n",
    "    test_acc = (test_Y == argmax_Y.float()).sum().item() / len(test_Y)\n",
    "    print(f\"Accuracy: {test_acc * 100}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdd7f51-63c3-4997-bf43-a573003f6863",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "\n",
    "\n",
    "with tqdm(total=testing_data_MC.max_iter, position=0, leave=True) as pbar:\n",
    "    for it in tqdm(range(testing_data_MC.max_iter), position = 0, leave=True):\n",
    "        #randomly sample the latent space\n",
    "        samples, labels = testing_data_MC.sample(iteration = it, _give_labels = True)\n",
    "        samples = samples.to(device)\n",
    "        # forward + backward + optimize\n",
    "        output_batch = classifier(samples)\n",
    "        for i in range(testing_data_MC.batch_size):\n",
    "            outputs[it*testing_data_MC.batch_size + i] = output_batch[i]\n",
    "print('Finished Running')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e877ba-f00f-4186-8f9d-0aaa025c4427",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Y     = testing_data_MC.labels.clone().detach().float().view(-1, 1).to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90700d43-1f05-4de7-abdf-8cfe347c1b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_Y = torch.softmax(outputs, 1)\n",
    "argmax_Y = torch.max(probs_Y, 1)[1].view(-1,1)\n",
    "test_acc = (test_Y == argmax_Y.float()).sum().item() / len(test_Y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001e4b99-fa4b-4704-97dc-580520e9539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01210034-1f5f-4532-9d79-6facaa413ef5",
   "metadata": {},
   "source": [
    "## Testing Classifier on DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7855c878-c171-41c8-9f15-5174841ef79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier_data(test_data, classifier):\n",
    "    outputs_data = torch.empty(test_data.num_events,2)\n",
    "    #Converting normalized DATA to classifier output\n",
    "    with tqdm(total=test_data.max_iter, position=0, leave=True) as pbar:\n",
    "        for it in tqdm(range(test_data.max_iter), position = 0, leave=True):\n",
    "            #randomly sample the latent space\n",
    "            samples, labels = test_data.sample(iteration = it, _give_labels = True)\n",
    "            samples = samples.to(device)\n",
    "            # forward + backward + optimize\n",
    "            output_batch = classifier(samples)\n",
    "            for i in range(test_data.batch_size):\n",
    "                outputs_data[it*test_data.batch_size + i] = output_batch[i]\n",
    "    probs_data = torch.softmax(outputs_data, 1)\n",
    "    argmax_Y = torch.max(probs_data, 1)[1].view(-1,1)\n",
    "    return argmax_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676b89f7-8028-42ed-9572-4db5057e7545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent_data = training_data_MC\n",
    "latent_data = full_pass_DATA_obj\n",
    "outputs_data = torch.empty(latent_data.num_events,2)\n",
    "\n",
    "#Converting normalized DATA to classifier output\n",
    "with tqdm(total=latent_data.max_iter, position=0, leave=True) as pbar:\n",
    "    for it in tqdm(range(latent_data.max_iter), position = 0, leave=True):\n",
    "        #randomly sample the latent space\n",
    "        samples, labels = latent_data.sample(iteration = it, _give_labels = True)\n",
    "        samples = samples.to(device)\n",
    "        # forward + backward + optimize\n",
    "        output_batch = classifier(samples)\n",
    "        for i in range(latent_data.batch_size):\n",
    "            outputs_data[it*latent_data.batch_size + i] = output_batch[i]\n",
    "print('Finished Running')\n",
    "probs_data = torch.softmax(outputs_data, 1)\n",
    "argmax_Y = torch.max(probs_data, 1)[1].view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f316cdd-7669-4487-9436-6e0a1a35e104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classified(masses, classes, label = \"none\",save = False, save_loc = \"plots/default.jpeg\", figsize = (18,4), bins = 100):\n",
    "    num_total = int(classes.size()[0])\n",
    "    num_signal = int(classes.sum())\n",
    "    signal = np.zeros(num_signal)\n",
    "    bg = np.zeros(num_total-num_signal)\n",
    "    bg_count, signal_count = 0, 0\n",
    "    for i in range(num_total):\n",
    "        if classes[i]:\n",
    "            signal[signal_count] = Lambda_masses[i]\n",
    "            signal_count+= 1\n",
    "        else:\n",
    "            bg[bg_count] = Lambda_masses[i]\n",
    "            bg_count += 1\n",
    "    histos, (h1,h2,h3) = plt.subplots(1,3, figsize = figsize)\n",
    "    h1.hist(signal, bins = bins, label = \"signal\", color = \"b\")\n",
    "    h2.hist(bg, bins = bins, label = \"background\", color = \"xkcd:orange\")\n",
    "    if(label != \"none\"):\n",
    "        h3.hist(training_data_MC.mass, bins = bins, label = label)\n",
    "    else:\n",
    "        h3.hist(training_data_MC.mass, bins = bins)\n",
    "\n",
    "    leg = histos.legend(title = \"Key\")\n",
    "    histos.show()\n",
    "    if(save):\n",
    "        histos.savefig(save_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c689612-8aeb-4221-92f4-4eb968bea9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_total = int(argmax_Y.size()[0])\n",
    "num_signal = int(argmax_Y.sum())\n",
    "signal = np.zeros(num_signal)\n",
    "bg = np.zeros(num_total-num_signal)\n",
    "bg_count, signal_count = 0, 0\n",
    "Lambda_masses = training_data_MC.mass\n",
    "for i in range(num_total):\n",
    "    if argmax_Y[i]:\n",
    "        signal[signal_count] = Lambda_masses[i]\n",
    "        signal_count+= 1\n",
    "    else:\n",
    "        bg[bg_count] = Lambda_masses[i]\n",
    "        bg_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e79b38-d2de-4707-ac27-2ca09dc67e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "histos, (h1,h2,h3) = plt.subplots(1,3, figsize = (18,4))\n",
    "h1.hist(signal, bins = 100, label = \"signal\", color = \"b\")\n",
    "h2.hist(bg, bins = 100, label = \"background\", color = \"xkcd:orange\")\n",
    "h3.hist(training_data_MC.mass, bins = 100, label = \"full spectrum, data\")\n",
    "\n",
    "leg = histos.legend(title = \"Key\")\n",
    "histos.show()\n",
    "# histos.savefig(\"plots/sig_vs_bg_full_pass_data.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25ca0b3-e8ab-480b-813f-945c22110b62",
   "metadata": {},
   "source": [
    "#### Checking what MC truth looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "db0752ff-3833-403e-98d2-6774f2e44dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "argmax_Y = transformed_latent_MC_obj.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6745db86-d5a0-4cad-9e02-f74ca5cc32a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_total = int(argmax_Y.size()[0])\n",
    "num_signal = int(argmax_Y.sum())\n",
    "signal = np.zeros(num_signal)\n",
    "bg = np.zeros(num_total-num_signal)\n",
    "bg_count, signal_count = 0, 0\n",
    "Lambda_masses = testing_data_MC.mass\n",
    "for i in range(num_total):\n",
    "    if argmax_Y[i]:\n",
    "        signal[signal_count] = Lambda_masses[i]\n",
    "        signal_count+= 1\n",
    "    else:\n",
    "        bg[bg_count] = Lambda_masses[i]\n",
    "        bg_count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
