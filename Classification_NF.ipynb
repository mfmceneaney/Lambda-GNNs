{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3423440-b266-4372-b031-e048056cc712",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/group/vossenlab/rck32/miniconda3/envs/venv/lib/python3.11/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/hpc/group/vossenlab/rck32/miniconda3/envs/venv/lib/python3.11/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/hpc/group/vossenlab/rck32/miniconda3/envs/venv/lib/python3.11/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/hpc/group/vossenlab/rck32/miniconda3/envs/venv/lib/python3.11/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "2023-06-28 14:49:13.785358: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-28 14:49:18.172088: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import normflows as nf\n",
    "from normflows import flows\n",
    "## Standard libraries\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as tdata\n",
    "import torch.optim as optim\n",
    "\n",
    "import dgl #NOTE: for dgl.batch and dgl.unbatch\n",
    "from dgl import save_graphs, load_graphs\n",
    "from dgl.data import DGLDataset\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from dgl.data.utils import save_info, load_info, Subset\n",
    "\n",
    "import umap\n",
    "reducer = umap.UMAP();\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Fetching the device that will be used throughout this notebook\n",
    "device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda:0\")\n",
    "print(\"Using device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c4c7f45-97b3-4cfb-a6b5-d917770f97d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "#custom imports\n",
    "from utils import load_graph_dataset, train, evaluate, GraphDataset, get_graph_dataset_info\n",
    "from models import GIN, HeteroGIN\n",
    "# from NF_utils import Latent_data, get_masked_affine, transform, train,plot_loss, test,plot_9_histos, plot_UMAP_sidebyside,plot_UMAP_overlay, create_latent_data\n",
    "from NF_utils import Latent_data, transform,plot_loss, test,plot_9_histos, plot_UMAP_sidebyside,plot_UMAP_overlay, create_latent_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9de4853-6f7b-4236-934b-ba37c9fe20e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''                                              '''\n",
    "'''     SETTING UP LATENT SPACE REPRESENTATION   '''\n",
    "'''                                              '''\n",
    "\n",
    "# Data and MC both have the same prefix\n",
    "prefix = \"/hpc/group/vossenlab/mfm45/.dgl/\"\n",
    "\n",
    "# MC inside Lambda_train_matched_jobs_outbending_cache_bg50nA_7_28_22__pT_phi_theta_beta_chi2_pid_status__Normalized\n",
    "MCdataset = \"Lambda_train_matched_jobs_outbending_cache_bg50nA_7_28_22__pT_phi_theta_beta_chi2_pid_status__Normalized\"\n",
    "\n",
    "# Data inside data_jobs_rga_fall2018_7_28_22__pT_phi_theta_beta_chi2_pid_status__Normalized\n",
    "DATAdataset = \"data_jobs_rga_fall2018_7_28_22__pT_phi_theta_beta_chi2_pid_status__Normalized\"\n",
    "\n",
    "max_events = 1e5\n",
    "split = 0.1\n",
    "nlayers = 2\n",
    "nmlp = 3\n",
    "hdim = 64\n",
    "nclasses, nfeatures, nfeatures_edge = get_graph_dataset_info(dataset=MCdataset, prefix=prefix)\n",
    "dropout = 0.8\n",
    "learn_eps = False\n",
    "batch = 256\n",
    "indices = None\n",
    "nworkers = 0\n",
    "npooling = \"max\"\n",
    "gpooling = \"max\"\n",
    "torch.manual_seed(0)\n",
    "\n",
    "#select model\n",
    "extractor = GIN(nlayers, nmlp, nfeatures,\n",
    "            hdim, nclasses, dropout, learn_eps, npooling, gpooling).to(device)\n",
    "extractor.load_state_dict(torch.load(\"logs/model_weights\",map_location=device))\n",
    "#select training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ade36de-98ea-48e7-8ca1-a8e60ffffd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No mode given, defaulting to training\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data_DATA = create_latent_data(DATAdataset, extractor,num_samples = 100)\n",
    "training_data_MC = create_latent_data(MCdataset, extractor,num_samples = 100)\n",
    "\n",
    "testing_data_DATA = create_latent_data(DATAdataset, extractor, mode = \"test\",num_samples = 100)\n",
    "testing_data_MC = create_latent_data(MCdataset, extractor, mode = \"test\",num_samples = 100)\n",
    "\n",
    "val_data_DATA = create_latent_data(DATAdataset, extractor, mode = \"val\",num_samples = 100)\n",
    "val_data_MC = create_latent_data(MCdataset, extractor, mode = \"val\",num_samples = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60808554-f05b-4dbb-b5b7-d082e4ec4740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(in_data, model, val = False,val_data = Latent_data(torch.empty(10000,71), torch.empty(10000,71)), num_epochs = 1, compact_num = 20):\n",
    "    # train the MC model\n",
    "    if(val):\n",
    "        val_data.set_batch_size(int(np.floor(val_data.num_events / in_data.max_iter)))\n",
    "        val_loss_hist = np.array([])\n",
    "        full_val_loss_hist = np.array([])\n",
    "    model.train()\n",
    "    loss_hist = np.array([])\n",
    "    full_loss_hist = np.array([])\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-5)\n",
    "    for i in range(num_epochs):\n",
    "        with tqdm(total=in_data.max_iter, position=0, leave=True) as pbar:\n",
    "            for it in tqdm(range(in_data.max_iter), position = 0, leave=True):\n",
    "                optimizer.zero_grad()\n",
    "                #randomly sample the latent space\n",
    "                samples = in_data.sample(iteration = it)\n",
    "                samples = samples.to(device)\n",
    "                loss = model.forward_kld(samples)\n",
    "                # Do backprop and optimizer step\n",
    "                if ~(torch.isnan(loss) | torch.isinf(loss)):\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                # Log loss\n",
    "                if~(torch.isnan(loss)):\n",
    "                    full_loss_hist = np.append(loss_hist, loss.to('cpu').data.numpy())\n",
    "                    if(loss < 1000):\n",
    "                        loss_hist = np.append(loss_hist, loss.to('cpu').data.numpy())\n",
    "                if(val):\n",
    "                    val_samples = val_data.sample(iteration = it)\n",
    "                    val_samples = val_samples.to(device)\n",
    "                    val_loss = model.forward_kld(val_samples)\n",
    "                    if~(torch.isnan(val_loss)):\n",
    "                        full_val_loss_hist = np.append(val_loss_hist, val_loss.to('cpu').data.numpy())\n",
    "                        if(val_loss < 1000):\n",
    "                            val_loss_hist = np.append(val_loss_hist, val_loss.to('cpu').data.numpy())\n",
    "    running_ttl = 0\n",
    "    compact_hist = np.array([])\n",
    "    j = 0\n",
    "    for i in range(loss_hist.size):\n",
    "        if(j != (i // compact_num)):\n",
    "            compact_hist = np.append(compact_hist,running_ttl / compact_num)\n",
    "            running_ttl = 0\n",
    "        j = i // compact_num\n",
    "        running_ttl += loss_hist[i]\n",
    "    if(val):\n",
    "        running_ttl_val = 0\n",
    "        compact_hist_val = np.array([])\n",
    "        j = 0\n",
    "        for i in range(val_loss_hist.size):\n",
    "            if(j != (i // compact_num)):\n",
    "                compact_hist_val = np.append(compact_hist_val,running_ttl_val / compact_num)\n",
    "                running_ttl_val = 0\n",
    "            j = i // compact_num\n",
    "            running_ttl_val += val_loss_hist[i]\n",
    "        return compact_hist, compact_hist_val, full_loss_hist, full_val_loss_hist\n",
    "    else:\n",
    "        return compact_hist, loss_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22695cfb-dc5b-4d4e-afa6-6e6978439d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_masked_affine(num_layers = 32):\n",
    "    #mask\n",
    "    b = torch.ones(71)\n",
    "    for i in range(b.size()[0]):\n",
    "        if i % 2 == 0:\n",
    "            b[i] = 0\n",
    "    masked_affine_flows = []\n",
    "    for i in range(num_layers):\n",
    "        s = nf.nets.MLP([71, 142, 142, 71])\n",
    "        t = nf.nets.MLP([71, 142, 142, 71])\n",
    "        if i % 2 == 0:\n",
    "            masked_affine_flows += [nf.flows.MaskedAffineFlow(b, t, s)]\n",
    "        else:\n",
    "            masked_affine_flows += [nf.flows.MaskedAffineFlow(1 - b, t, s)]\n",
    "    return masked_affine_flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985cd965-dcba-4e55-b37e-728155876507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTING UP DATA MODEL\n",
    "\n",
    "masked_affine_flows_train_DATA = get_masked_affine(48)\n",
    "distribution_DATA = nf.distributions.DiagGaussian(training_data_DATA.latent_size, trainable = False)\n",
    "masked_affine_model_DATA = nf.NormalizingFlow(q0=distribution_DATA, flows=masked_affine_flows_train_DATA)\n",
    "DATA_model = masked_affine_model_DATA.to(device)\n",
    "\n",
    "# SETTING UP MC MODEL\n",
    "\n",
    "masked_affine_flows_train_MC = get_masked_affine(48)\n",
    "distribution_MC = nf.distributions.DiagGaussian(training_data_MC.latent_size, trainable = False)\n",
    "masked_affine_model_MC = nf.NormalizingFlow(q0=distribution_MC, flows=masked_affine_flows_train_MC)\n",
    "MC_model = masked_affine_model_MC.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e270e1e4-478d-4a9e-b46d-41d4b470f296",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1120/1120 [01:51<00:00, 10.02it/s]\n",
      "  0%|          | 0/1120 [01:51<?, ?it/s]\n",
      "100%|██████████| 1120/1120 [01:57<00:00,  9.55it/s]\n",
      "  0%|          | 0/1120 [01:57<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "application/pdf": "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",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600.504688pt\" height=\"585.478125pt\" viewBox=\"0 0 600.504688 585.478125\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2023-06-28T15:00:50.709784</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.1, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 585.478125 \n",
       "L 600.504688 585.478125 \n",
       "L 600.504688 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 35.304688 561.6 \n",
       "L 593.304688 561.6 \n",
       "L 593.304688 7.2 \n",
       "L 35.304688 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"m051cf10c9e\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m051cf10c9e\" x=\"60.668324\" y=\"561.6\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(57.487074 576.198438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m051cf10c9e\" x=\"152.899729\" y=\"561.6\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(146.537229 576.198438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m051cf10c9e\" x=\"245.131134\" y=\"561.6\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 40 -->\n",
       "      <g transform=\"translate(238.768634 576.198438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m051cf10c9e\" x=\"337.362539\" y=\"561.6\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 60 -->\n",
       "      <g transform=\"translate(331.000039 576.198438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
       "Q 1688 2584 1439 2293 \n",
       "Q 1191 2003 1191 1497 \n",
       "Q 1191 994 1439 701 \n",
       "Q 1688 409 2113 409 \n",
       "Q 2538 409 2786 701 \n",
       "Q 3034 994 3034 1497 \n",
       "Q 3034 2003 2786 2293 \n",
       "Q 2538 2584 2113 2584 \n",
       "z\n",
       "M 3366 4563 \n",
       "L 3366 3988 \n",
       "Q 3128 4100 2886 4159 \n",
       "Q 2644 4219 2406 4219 \n",
       "Q 1781 4219 1451 3797 \n",
       "Q 1122 3375 1075 2522 \n",
       "Q 1259 2794 1537 2939 \n",
       "Q 1816 3084 2150 3084 \n",
       "Q 2853 3084 3261 2657 \n",
       "Q 3669 2231 3669 1497 \n",
       "Q 3669 778 3244 343 \n",
       "Q 2819 -91 2113 -91 \n",
       "Q 1303 -91 875 529 \n",
       "Q 447 1150 447 2328 \n",
       "Q 447 3434 972 4092 \n",
       "Q 1497 4750 2381 4750 \n",
       "Q 2619 4750 2861 4703 \n",
       "Q 3103 4656 3366 4563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-36\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m051cf10c9e\" x=\"429.593944\" y=\"561.6\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 80 -->\n",
       "      <g transform=\"translate(423.231444 576.198438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \n",
       "Q 1584 2216 1326 1975 \n",
       "Q 1069 1734 1069 1313 \n",
       "Q 1069 891 1326 650 \n",
       "Q 1584 409 2034 409 \n",
       "Q 2484 409 2743 651 \n",
       "Q 3003 894 3003 1313 \n",
       "Q 3003 1734 2745 1975 \n",
       "Q 2488 2216 2034 2216 \n",
       "z\n",
       "M 1403 2484 \n",
       "Q 997 2584 770 2862 \n",
       "Q 544 3141 544 3541 \n",
       "Q 544 4100 942 4425 \n",
       "Q 1341 4750 2034 4750 \n",
       "Q 2731 4750 3128 4425 \n",
       "Q 3525 4100 3525 3541 \n",
       "Q 3525 3141 3298 2862 \n",
       "Q 3072 2584 2669 2484 \n",
       "Q 3125 2378 3379 2068 \n",
       "Q 3634 1759 3634 1313 \n",
       "Q 3634 634 3220 271 \n",
       "Q 2806 -91 2034 -91 \n",
       "Q 1263 -91 848 271 \n",
       "Q 434 634 434 1313 \n",
       "Q 434 1759 690 2068 \n",
       "Q 947 2378 1403 2484 \n",
       "z\n",
       "M 1172 3481 \n",
       "Q 1172 3119 1398 2916 \n",
       "Q 1625 2713 2034 2713 \n",
       "Q 2441 2713 2670 2916 \n",
       "Q 2900 3119 2900 3481 \n",
       "Q 2900 3844 2670 4047 \n",
       "Q 2441 4250 2034 4250 \n",
       "Q 1625 4250 1398 4047 \n",
       "Q 1172 3844 1172 3481 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-38\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m051cf10c9e\" x=\"521.825349\" y=\"561.6\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 100 -->\n",
       "      <g transform=\"translate(512.281599 576.198438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <defs>\n",
       "       <path id=\"m64270916d1\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m64270916d1\" x=\"35.304688\" y=\"536.651257\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- −40 -->\n",
       "      <g transform=\"translate(7.2 540.450476) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \n",
       "L 4684 2272 \n",
       "L 4684 1741 \n",
       "L 678 1741 \n",
       "L 678 2272 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-34\" x=\"83.789062\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"147.412109\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m64270916d1\" x=\"35.304688\" y=\"470.23641\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- −20 -->\n",
       "      <g transform=\"translate(7.2 474.035629) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"83.789062\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"147.412109\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m64270916d1\" x=\"35.304688\" y=\"403.821563\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(21.942187 407.620782) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m64270916d1\" x=\"35.304688\" y=\"337.406716\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(15.579687 341.205934) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m64270916d1\" x=\"35.304688\" y=\"270.991869\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 40 -->\n",
       "      <g transform=\"translate(15.579687 274.791087) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m64270916d1\" x=\"35.304688\" y=\"204.577021\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 60 -->\n",
       "      <g transform=\"translate(15.579687 208.37624) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-36\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m64270916d1\" x=\"35.304688\" y=\"138.162174\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 80 -->\n",
       "      <g transform=\"translate(15.579687 141.961393) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-38\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_8\">\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m64270916d1\" x=\"35.304688\" y=\"71.747327\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 100 -->\n",
       "      <g transform=\"translate(9.217187 75.546546) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_15\">\n",
       "    <path d=\"M 60.668324 32.4 \n",
       "L 65.279894 226.170569 \n",
       "L 69.891464 292.623772 \n",
       "L 74.503035 326.179221 \n",
       "L 79.114605 350.746067 \n",
       "L 83.726175 367.145091 \n",
       "L 88.337745 378.308471 \n",
       "L 92.949316 379.348589 \n",
       "L 97.560886 390.230312 \n",
       "L 102.172456 403.707898 \n",
       "L 106.784026 409.380905 \n",
       "L 111.395597 393.914034 \n",
       "L 116.007167 413.010569 \n",
       "L 120.618737 415.269881 \n",
       "L 125.230307 427.230672 \n",
       "L 129.841878 430.66052 \n",
       "L 134.453448 430.913802 \n",
       "L 139.065018 436.914675 \n",
       "L 143.676588 444.208268 \n",
       "L 148.288159 445.263449 \n",
       "L 152.899729 444.801309 \n",
       "L 157.511299 447.417521 \n",
       "L 162.122869 445.375443 \n",
       "L 166.73444 449.642545 \n",
       "L 171.34601 456.350102 \n",
       "L 175.95758 455.600296 \n",
       "L 180.56915 458.211072 \n",
       "L 185.180721 445.662911 \n",
       "L 189.792291 461.499239 \n",
       "L 194.403861 459.413383 \n",
       "L 199.015431 467.255779 \n",
       "L 203.627002 466.711776 \n",
       "L 208.238572 472.791407 \n",
       "L 212.850142 472.178424 \n",
       "L 217.461712 471.907185 \n",
       "L 222.073283 471.148571 \n",
       "L 226.684853 476.752828 \n",
       "L 231.296423 451.36593 \n",
       "L 235.907993 469.829594 \n",
       "L 240.519564 480.27998 \n",
       "L 245.131134 481.140014 \n",
       "L 249.742704 482.06245 \n",
       "L 254.354274 487.252562 \n",
       "L 258.965845 482.05616 \n",
       "L 263.577415 483.775677 \n",
       "L 268.188985 486.463475 \n",
       "L 272.800555 488.775381 \n",
       "L 277.412126 486.587079 \n",
       "L 282.023696 494.645675 \n",
       "L 286.635266 472.505628 \n",
       "L 291.246836 490.177344 \n",
       "L 295.858407 491.984631 \n",
       "L 300.469977 492.45836 \n",
       "L 305.081547 493.370305 \n",
       "L 309.693117 495.276412 \n",
       "L 314.304688 495.456413 \n",
       "L 318.916258 489.44441 \n",
       "L 323.527828 502.01486 \n",
       "L 328.139398 500.968166 \n",
       "L 332.750968 502.13661 \n",
       "L 337.362539 502.086922 \n",
       "L 341.974109 500.579092 \n",
       "L 346.585679 505.350198 \n",
       "L 351.197249 501.476221 \n",
       "L 355.80882 500.444355 \n",
       "L 360.42039 509.548131 \n",
       "L 365.03196 507.685238 \n",
       "L 369.64353 503.333073 \n",
       "L 374.255101 505.288553 \n",
       "L 378.866671 502.707811 \n",
       "L 383.478241 511.30487 \n",
       "L 388.089811 507.475129 \n",
       "L 392.701382 512.753015 \n",
       "L 397.312952 510.103139 \n",
       "L 401.924522 513.623606 \n",
       "L 406.536092 513.880488 \n",
       "L 411.147663 508.245257 \n",
       "L 415.759233 515.045687 \n",
       "L 420.370803 517.477933 \n",
       "L 424.982373 511.701234 \n",
       "L 429.593944 512.241442 \n",
       "L 434.205514 516.168129 \n",
       "L 438.817084 519.905619 \n",
       "L 443.428654 519.376885 \n",
       "L 448.040225 519.847759 \n",
       "L 452.651795 514.814113 \n",
       "L 457.263365 522.185533 \n",
       "L 461.874935 518.576109 \n",
       "L 466.486506 522.467565 \n",
       "L 471.098076 521.376682 \n",
       "L 475.709646 517.537483 \n",
       "L 480.321216 517.721125 \n",
       "L 484.932787 520.875562 \n",
       "L 489.544357 525.821607 \n",
       "L 494.155927 525.671295 \n",
       "L 498.767497 527.600698 \n",
       "L 503.379068 528.365535 \n",
       "L 507.990638 517.769724 \n",
       "L 512.602208 529.289412 \n",
       "L 517.213778 529.851317 \n",
       "L 521.825349 529.566257 \n",
       "L 526.436919 527.936705 \n",
       "L 531.048489 523.732441 \n",
       "L 535.660059 524.835068 \n",
       "L 540.27163 529.844404 \n",
       "L 544.8832 532.525797 \n",
       "L 549.49477 534.029414 \n",
       "L 554.10634 530.191151 \n",
       "L 558.717911 530.214734 \n",
       "L 563.329481 529.803721 \n",
       "L 567.941051 531.085945 \n",
       "\" clip-path=\"url(#pd2d6791fba)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 2; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_16\">\n",
       "    <path d=\"M 60.668324 44.226064 \n",
       "L 65.279894 231.8366 \n",
       "L 69.891464 291.828199 \n",
       "L 74.503035 324.833645 \n",
       "L 79.114605 356.319522 \n",
       "L 83.726175 362.705064 \n",
       "L 88.337745 376.733873 \n",
       "L 92.949316 376.446954 \n",
       "L 97.560886 385.909434 \n",
       "L 102.172456 405.155022 \n",
       "L 106.784026 413.121656 \n",
       "L 111.395597 388.761333 \n",
       "L 116.007167 409.384954 \n",
       "L 120.618737 412.529979 \n",
       "L 125.230307 421.349515 \n",
       "L 129.841878 430.756204 \n",
       "L 134.453448 435.721632 \n",
       "L 139.065018 432.960899 \n",
       "L 143.676588 441.250875 \n",
       "L 148.288159 446.607223 \n",
       "L 152.899729 454.255367 \n",
       "L 157.511299 450.657644 \n",
       "L 162.122869 444.34758 \n",
       "L 166.73444 452.471583 \n",
       "L 171.34601 468.800827 \n",
       "L 175.95758 464.413956 \n",
       "L 180.56915 461.874075 \n",
       "L 185.180721 454.235962 \n",
       "L 189.792291 459.947364 \n",
       "L 194.403861 459.869064 \n",
       "L 199.015431 469.515526 \n",
       "L 203.627002 469.434806 \n",
       "L 208.238572 473.117408 \n",
       "L 212.850142 474.432053 \n",
       "L 217.461712 473.084945 \n",
       "L 222.073283 470.125096 \n",
       "L 226.684853 475.69088 \n",
       "L 231.296423 440.458085 \n",
       "L 235.907993 468.81687 \n",
       "L 240.519564 486.957703 \n",
       "L 245.131134 482.873132 \n",
       "L 249.742704 491.220147 \n",
       "L 254.354274 493.360345 \n",
       "L 258.965845 475.109228 \n",
       "L 263.577415 482.683314 \n",
       "L 268.188985 493.216456 \n",
       "L 272.800555 489.396427 \n",
       "L 277.412126 493.828391 \n",
       "L 282.023696 495.710145 \n",
       "L 286.635266 471.856017 \n",
       "L 291.246836 487.871231 \n",
       "L 295.858407 497.820255 \n",
       "L 300.469977 498.193012 \n",
       "L 305.081547 495.392404 \n",
       "L 309.693117 501.231321 \n",
       "L 314.304688 501.901467 \n",
       "L 318.916258 487.217614 \n",
       "L 323.527828 503.808761 \n",
       "L 328.139398 499.687357 \n",
       "L 332.750968 502.042296 \n",
       "L 337.362539 507.098031 \n",
       "L 341.974109 499.407562 \n",
       "L 346.585679 498.820473 \n",
       "L 351.197249 499.661123 \n",
       "L 355.80882 493.853755 \n",
       "L 360.42039 509.523311 \n",
       "L 365.03196 510.19067 \n",
       "L 369.64353 501.608925 \n",
       "L 374.255101 502.720348 \n",
       "L 378.866671 501.666047 \n",
       "L 383.478241 505.682849 \n",
       "L 388.089811 508.529161 \n",
       "L 392.701382 515.432378 \n",
       "L 397.312952 507.911074 \n",
       "L 401.924522 511.02343 \n",
       "L 406.536092 518.36786 \n",
       "L 411.147663 520.874519 \n",
       "L 415.759233 520.663504 \n",
       "L 420.370803 516.531128 \n",
       "L 424.982373 518.876501 \n",
       "L 429.593944 525.643423 \n",
       "L 434.205514 527.241026 \n",
       "L 438.817084 526.356971 \n",
       "L 443.428654 528.836464 \n",
       "L 448.040225 517.442058 \n",
       "L 452.651795 517.248628 \n",
       "L 457.263365 524.339997 \n",
       "L 461.874935 520.840504 \n",
       "L 466.486506 521.371853 \n",
       "L 471.098076 519.352751 \n",
       "L 475.709646 516.959996 \n",
       "L 480.321216 517.813579 \n",
       "L 484.932787 517.467194 \n",
       "L 489.544357 515.132266 \n",
       "L 494.155927 523.164205 \n",
       "L 498.767497 535.232869 \n",
       "L 503.379068 528.429386 \n",
       "L 507.990638 527.129353 \n",
       "L 512.602208 536.4 \n",
       "L 517.213778 523.681051 \n",
       "L 521.825349 527.899641 \n",
       "L 526.436919 535.741767 \n",
       "L 531.048489 522.929081 \n",
       "L 535.660059 532.030476 \n",
       "L 540.27163 531.097432 \n",
       "L 544.8832 533.736015 \n",
       "L 549.49477 532.841766 \n",
       "L 554.10634 535.445209 \n",
       "L 558.717911 534.793491 \n",
       "L 563.329481 529.47765 \n",
       "L 567.941051 536.318549 \n",
       "\" clip-path=\"url(#pd2d6791fba)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 2; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 35.304688 561.6 \n",
       "L 35.304688 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 593.304688 561.6 \n",
       "L 593.304688 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 35.304688 561.6 \n",
       "L 593.304688 561.6 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 35.304688 7.2 \n",
       "L 593.304688 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 516.2 44.55625 \n",
       "L 586.304688 44.55625 \n",
       "Q 588.304688 44.55625 588.304688 42.55625 \n",
       "L 588.304688 14.2 \n",
       "Q 588.304688 12.2 586.304688 12.2 \n",
       "L 516.2 12.2 \n",
       "Q 514.2 12.2 514.2 14.2 \n",
       "L 514.2 42.55625 \n",
       "Q 514.2 44.55625 516.2 44.55625 \n",
       "z\n",
       "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_17\">\n",
       "     <path d=\"M 518.2 20.298438 \n",
       "L 528.2 20.298438 \n",
       "L 538.2 20.298438 \n",
       "\" style=\"fill: none; stroke: #1f77b4; stroke-width: 2; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_15\">\n",
       "     <!-- MC loss -->\n",
       "     <g transform=\"translate(546.2 23.798438) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-4d\" d=\"M 628 4666 \n",
       "L 1569 4666 \n",
       "L 2759 1491 \n",
       "L 3956 4666 \n",
       "L 4897 4666 \n",
       "L 4897 0 \n",
       "L 4281 0 \n",
       "L 4281 4097 \n",
       "L 3078 897 \n",
       "L 2444 897 \n",
       "L 1241 4097 \n",
       "L 1241 0 \n",
       "L 628 0 \n",
       "L 628 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-43\" d=\"M 4122 4306 \n",
       "L 4122 3641 \n",
       "Q 3803 3938 3442 4084 \n",
       "Q 3081 4231 2675 4231 \n",
       "Q 1875 4231 1450 3742 \n",
       "Q 1025 3253 1025 2328 \n",
       "Q 1025 1406 1450 917 \n",
       "Q 1875 428 2675 428 \n",
       "Q 3081 428 3442 575 \n",
       "Q 3803 722 4122 1019 \n",
       "L 4122 359 \n",
       "Q 3791 134 3420 21 \n",
       "Q 3050 -91 2638 -91 \n",
       "Q 1578 -91 968 557 \n",
       "Q 359 1206 359 2328 \n",
       "Q 359 3453 968 4101 \n",
       "Q 1578 4750 2638 4750 \n",
       "Q 3056 4750 3426 4639 \n",
       "Q 3797 4528 4122 4306 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-4d\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-43\" x=\"86.279297\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" x=\"156.103516\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" x=\"187.890625\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"215.673828\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"276.855469\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"328.955078\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_18\">\n",
       "     <path d=\"M 518.2 34.976563 \n",
       "L 528.2 34.976563 \n",
       "L 538.2 34.976563 \n",
       "\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 2; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_16\">\n",
       "     <!-- val -->\n",
       "     <g transform=\"translate(546.2 38.476563) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-76\" d=\"M 191 3500 \n",
       "L 800 3500 \n",
       "L 1894 563 \n",
       "L 2988 3500 \n",
       "L 3597 3500 \n",
       "L 2284 0 \n",
       "L 1503 0 \n",
       "L 191 3500 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-76\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pd2d6791fba\">\n",
       "   <rect x=\"35.304688\" y=\"7.2\" width=\"558\" height=\"554.4\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowest Loss: -39.21046466827393\n"
     ]
    }
   ],
   "source": [
    "# TRAINING MC\n",
    "loss_hist, val_hist, full_loss_hist, full_val_hist = train(training_data_MC, MC_model, val = True, val_data = val_data_MC, num_epochs = 2, compact_num = 20)\n",
    "plot_loss(loss_hist, label = \"MC loss\",plot_val = True, val_loss_hist = val_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe296596-06aa-4c75-b83b-5b4de484d5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1120/1120 [02:07<00:00,  8.80it/s]\n",
      "  0%|          | 0/1120 [02:07<?, ?it/s]\n",
      "100%|██████████| 1120/1120 [02:03<00:00,  9.04it/s]\n",
      "  0%|          | 0/1120 [02:03<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "application/pdf": "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",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600.504688pt\" height=\"585.478125pt\" viewBox=\"0 0 600.504688 585.478125\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2023-06-28T15:05:02.744603</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.1, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 585.478125 \n",
       "L 600.504688 585.478125 \n",
       "L 600.504688 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 35.304688 561.6 \n",
       "L 593.304688 561.6 \n",
       "L 593.304688 7.2 \n",
       "L 35.304688 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"m922711e435\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m922711e435\" x=\"60.668324\" y=\"561.6\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(57.487074 576.198438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m922711e435\" x=\"152.899729\" y=\"561.6\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(146.537229 576.198438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m922711e435\" x=\"245.131134\" y=\"561.6\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 40 -->\n",
       "      <g transform=\"translate(238.768634 576.198438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m922711e435\" x=\"337.362539\" y=\"561.6\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 60 -->\n",
       "      <g transform=\"translate(331.000039 576.198438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
       "Q 1688 2584 1439 2293 \n",
       "Q 1191 2003 1191 1497 \n",
       "Q 1191 994 1439 701 \n",
       "Q 1688 409 2113 409 \n",
       "Q 2538 409 2786 701 \n",
       "Q 3034 994 3034 1497 \n",
       "Q 3034 2003 2786 2293 \n",
       "Q 2538 2584 2113 2584 \n",
       "z\n",
       "M 3366 4563 \n",
       "L 3366 3988 \n",
       "Q 3128 4100 2886 4159 \n",
       "Q 2644 4219 2406 4219 \n",
       "Q 1781 4219 1451 3797 \n",
       "Q 1122 3375 1075 2522 \n",
       "Q 1259 2794 1537 2939 \n",
       "Q 1816 3084 2150 3084 \n",
       "Q 2853 3084 3261 2657 \n",
       "Q 3669 2231 3669 1497 \n",
       "Q 3669 778 3244 343 \n",
       "Q 2819 -91 2113 -91 \n",
       "Q 1303 -91 875 529 \n",
       "Q 447 1150 447 2328 \n",
       "Q 447 3434 972 4092 \n",
       "Q 1497 4750 2381 4750 \n",
       "Q 2619 4750 2861 4703 \n",
       "Q 3103 4656 3366 4563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-36\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m922711e435\" x=\"429.593944\" y=\"561.6\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 80 -->\n",
       "      <g transform=\"translate(423.231444 576.198438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \n",
       "Q 1584 2216 1326 1975 \n",
       "Q 1069 1734 1069 1313 \n",
       "Q 1069 891 1326 650 \n",
       "Q 1584 409 2034 409 \n",
       "Q 2484 409 2743 651 \n",
       "Q 3003 894 3003 1313 \n",
       "Q 3003 1734 2745 1975 \n",
       "Q 2488 2216 2034 2216 \n",
       "z\n",
       "M 1403 2484 \n",
       "Q 997 2584 770 2862 \n",
       "Q 544 3141 544 3541 \n",
       "Q 544 4100 942 4425 \n",
       "Q 1341 4750 2034 4750 \n",
       "Q 2731 4750 3128 4425 \n",
       "Q 3525 4100 3525 3541 \n",
       "Q 3525 3141 3298 2862 \n",
       "Q 3072 2584 2669 2484 \n",
       "Q 3125 2378 3379 2068 \n",
       "Q 3634 1759 3634 1313 \n",
       "Q 3634 634 3220 271 \n",
       "Q 2806 -91 2034 -91 \n",
       "Q 1263 -91 848 271 \n",
       "Q 434 634 434 1313 \n",
       "Q 434 1759 690 2068 \n",
       "Q 947 2378 1403 2484 \n",
       "z\n",
       "M 1172 3481 \n",
       "Q 1172 3119 1398 2916 \n",
       "Q 1625 2713 2034 2713 \n",
       "Q 2441 2713 2670 2916 \n",
       "Q 2900 3119 2900 3481 \n",
       "Q 2900 3844 2670 4047 \n",
       "Q 2441 4250 2034 4250 \n",
       "Q 1625 4250 1398 4047 \n",
       "Q 1172 3844 1172 3481 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-38\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m922711e435\" x=\"521.825349\" y=\"561.6\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 100 -->\n",
       "      <g transform=\"translate(512.281599 576.198438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <defs>\n",
       "       <path id=\"mcafd7dd27e\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcafd7dd27e\" x=\"35.304688\" y=\"560.004984\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- −50 -->\n",
       "      <g transform=\"translate(7.2 563.804203) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \n",
       "L 4684 2272 \n",
       "L 4684 1741 \n",
       "L 678 1741 \n",
       "L 678 2272 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"83.789062\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"147.412109\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcafd7dd27e\" x=\"35.304688\" y=\"483.654822\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- −25 -->\n",
       "      <g transform=\"translate(7.2 487.454041) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"83.789062\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"147.412109\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcafd7dd27e\" x=\"35.304688\" y=\"407.30466\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(21.942187 411.103879) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcafd7dd27e\" x=\"35.304688\" y=\"330.954498\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 25 -->\n",
       "      <g transform=\"translate(15.579687 334.753716) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcafd7dd27e\" x=\"35.304688\" y=\"254.604336\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 50 -->\n",
       "      <g transform=\"translate(15.579687 258.403554) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcafd7dd27e\" x=\"35.304688\" y=\"178.254173\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 75 -->\n",
       "      <g transform=\"translate(15.579687 182.053392) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-37\" d=\"M 525 4666 \n",
       "L 3525 4666 \n",
       "L 3525 4397 \n",
       "L 1831 0 \n",
       "L 1172 0 \n",
       "L 2766 4134 \n",
       "L 525 4134 \n",
       "L 525 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-37\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcafd7dd27e\" x=\"35.304688\" y=\"101.904011\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 100 -->\n",
       "      <g transform=\"translate(9.217187 105.70323) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_8\">\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mcafd7dd27e\" x=\"35.304688\" y=\"25.553849\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 125 -->\n",
       "      <g transform=\"translate(9.217187 29.353068) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_15\">\n",
       "    <path d=\"M 60.668324 36.497876 \n",
       "L 65.279894 205.468395 \n",
       "L 69.891464 292.400365 \n",
       "L 74.503035 329.023066 \n",
       "L 79.114605 357.981506 \n",
       "L 83.726175 370.702668 \n",
       "L 88.337745 383.072218 \n",
       "L 92.949316 386.618802 \n",
       "L 97.560886 400.874375 \n",
       "L 102.172456 409.615176 \n",
       "L 106.784026 409.926319 \n",
       "L 111.395597 419.006992 \n",
       "L 116.007167 425.826451 \n",
       "L 120.618737 426.582065 \n",
       "L 125.230307 431.933327 \n",
       "L 129.841878 434.000509 \n",
       "L 134.453448 440.501962 \n",
       "L 139.065018 439.500335 \n",
       "L 143.676588 446.622521 \n",
       "L 148.288159 450.353335 \n",
       "L 152.899729 449.197593 \n",
       "L 157.511299 453.819545 \n",
       "L 162.122869 451.405811 \n",
       "L 166.73444 450.892074 \n",
       "L 171.34601 455.624072 \n",
       "L 175.95758 461.955472 \n",
       "L 180.56915 462.306946 \n",
       "L 185.180721 464.505082 \n",
       "L 189.792291 460.768078 \n",
       "L 194.403861 466.385542 \n",
       "L 199.015431 468.487737 \n",
       "L 203.627002 468.945757 \n",
       "L 208.238572 475.996105 \n",
       "L 212.850142 471.76208 \n",
       "L 217.461712 476.257061 \n",
       "L 222.073283 478.59553 \n",
       "L 226.684853 480.264837 \n",
       "L 231.296423 481.320345 \n",
       "L 235.907993 474.692458 \n",
       "L 240.519564 478.494331 \n",
       "L 245.131134 483.232037 \n",
       "L 249.742704 479.849086 \n",
       "L 254.354274 483.072106 \n",
       "L 258.965845 483.846854 \n",
       "L 263.577415 488.304326 \n",
       "L 268.188985 481.199427 \n",
       "L 272.800555 477.764896 \n",
       "L 277.412126 483.966549 \n",
       "L 282.023696 491.516314 \n",
       "L 286.635266 487.698609 \n",
       "L 291.246836 492.502009 \n",
       "L 295.858407 494.447082 \n",
       "L 300.469977 494.003802 \n",
       "L 305.081547 492.064249 \n",
       "L 309.693117 495.865964 \n",
       "L 314.304688 498.929533 \n",
       "L 318.916258 497.602624 \n",
       "L 323.527828 498.720806 \n",
       "L 328.139398 501.771805 \n",
       "L 332.750968 497.251545 \n",
       "L 337.362539 492.872923 \n",
       "L 341.974109 493.652876 \n",
       "L 346.585679 499.045456 \n",
       "L 351.197249 504.536599 \n",
       "L 355.80882 508.405931 \n",
       "L 360.42039 508.108481 \n",
       "L 365.03196 506.762477 \n",
       "L 369.64353 512.418213 \n",
       "L 374.255101 503.373876 \n",
       "L 378.866671 505.167454 \n",
       "L 383.478241 511.566422 \n",
       "L 388.089811 502.009937 \n",
       "L 392.701382 508.173508 \n",
       "L 397.312952 510.740236 \n",
       "L 401.924522 512.238825 \n",
       "L 406.536092 518.948832 \n",
       "L 411.147663 517.161902 \n",
       "L 415.759233 518.386783 \n",
       "L 420.370803 519.19541 \n",
       "L 424.982373 510.025925 \n",
       "L 429.593944 510.795392 \n",
       "L 434.205514 516.740375 \n",
       "L 438.817084 520.375934 \n",
       "L 443.428654 518.661028 \n",
       "L 448.040225 520.124764 \n",
       "L 452.651795 519.725766 \n",
       "L 457.263365 525.963358 \n",
       "L 461.874935 515.411926 \n",
       "L 466.486506 522.614121 \n",
       "L 471.098076 525.06728 \n",
       "L 475.709646 525.953439 \n",
       "L 480.321216 520.493514 \n",
       "L 484.932787 523.830567 \n",
       "L 489.544357 525.693704 \n",
       "L 494.155927 520.931235 \n",
       "L 498.767497 525.516269 \n",
       "L 503.379068 525.440229 \n",
       "L 507.990638 516.998231 \n",
       "L 512.602208 524.810721 \n",
       "L 517.213778 530.388922 \n",
       "L 521.825349 527.669258 \n",
       "L 526.436919 526.254696 \n",
       "L 531.048489 527.788608 \n",
       "L 535.660059 529.145869 \n",
       "L 540.27163 532.419901 \n",
       "L 544.8832 531.228059 \n",
       "L 549.49477 531.651264 \n",
       "L 554.10634 529.330908 \n",
       "L 558.717911 532.348269 \n",
       "L 563.329481 536.4 \n",
       "L 567.941051 533.653941 \n",
       "\" clip-path=\"url(#p66fd2ceb4e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 2; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_16\">\n",
       "    <path d=\"M 60.668324 32.4 \n",
       "L 65.279894 190.166798 \n",
       "L 69.891464 283.292704 \n",
       "L 74.503035 335.330484 \n",
       "L 79.114605 358.294681 \n",
       "L 83.726175 373.463949 \n",
       "L 88.337745 382.796263 \n",
       "L 92.949316 388.419943 \n",
       "L 97.560886 396.986153 \n",
       "L 102.172456 412.48204 \n",
       "L 106.784026 410.792897 \n",
       "L 111.395597 416.579446 \n",
       "L 116.007167 425.639829 \n",
       "L 120.618737 432.193827 \n",
       "L 125.230307 436.172561 \n",
       "L 129.841878 435.362307 \n",
       "L 134.453448 443.740097 \n",
       "L 139.065018 446.525318 \n",
       "L 143.676588 451.648006 \n",
       "L 148.288159 443.536199 \n",
       "L 152.899729 445.550054 \n",
       "L 157.511299 455.959913 \n",
       "L 162.122869 452.662521 \n",
       "L 166.73444 455.395841 \n",
       "L 171.34601 459.681444 \n",
       "L 175.95758 459.966843 \n",
       "L 180.56915 459.600777 \n",
       "L 185.180721 458.4014 \n",
       "L 189.792291 466.286406 \n",
       "L 194.403861 465.534306 \n",
       "L 199.015431 475.314658 \n",
       "L 203.627002 477.899311 \n",
       "L 208.238572 480.636264 \n",
       "L 212.850142 468.921611 \n",
       "L 217.461712 469.167893 \n",
       "L 222.073283 474.951369 \n",
       "L 226.684853 472.325156 \n",
       "L 231.296423 481.370854 \n",
       "L 235.907993 481.71186 \n",
       "L 240.519564 478.755451 \n",
       "L 245.131134 476.198795 \n",
       "L 249.742704 475.029824 \n",
       "L 254.354274 492.021618 \n",
       "L 258.965845 489.334639 \n",
       "L 263.577415 480.428334 \n",
       "L 268.188985 470.593969 \n",
       "L 272.800555 480.048833 \n",
       "L 277.412126 478.2121 \n",
       "L 282.023696 486.472456 \n",
       "L 286.635266 480.907373 \n",
       "L 291.246836 485.057115 \n",
       "L 295.858407 495.678667 \n",
       "L 300.469977 492.766889 \n",
       "L 305.081547 485.423392 \n",
       "L 309.693117 491.063265 \n",
       "L 314.304688 500.012732 \n",
       "L 318.916258 503.223982 \n",
       "L 323.527828 499.569852 \n",
       "L 328.139398 497.716912 \n",
       "L 332.750968 504.009033 \n",
       "L 337.362539 496.954931 \n",
       "L 341.974109 494.84327 \n",
       "L 346.585679 500.937767 \n",
       "L 351.197249 507.342317 \n",
       "L 355.80882 504.290159 \n",
       "L 360.42039 510.296343 \n",
       "L 365.03196 511.243173 \n",
       "L 369.64353 507.058048 \n",
       "L 374.255101 502.869351 \n",
       "L 378.866671 511.161959 \n",
       "L 383.478241 518.335629 \n",
       "L 388.089811 503.453319 \n",
       "L 392.701382 507.773549 \n",
       "L 397.312952 524.616368 \n",
       "L 401.924522 516.223885 \n",
       "L 406.536092 513.576643 \n",
       "L 411.147663 514.369935 \n",
       "L 415.759233 520.576783 \n",
       "L 420.370803 519.871676 \n",
       "L 424.982373 515.304688 \n",
       "L 429.593944 513.71419 \n",
       "L 434.205514 515.058488 \n",
       "L 438.817084 518.626731 \n",
       "L 443.428654 512.780076 \n",
       "L 448.040225 525.741882 \n",
       "L 452.651795 518.95794 \n",
       "L 457.263365 533.525905 \n",
       "L 461.874935 526.808057 \n",
       "L 466.486506 529.161212 \n",
       "L 471.098076 521.185382 \n",
       "L 475.709646 518.279158 \n",
       "L 480.321216 515.915498 \n",
       "L 484.932787 512.547859 \n",
       "L 489.544357 521.141441 \n",
       "L 494.155927 528.351405 \n",
       "L 498.767497 525.342855 \n",
       "L 503.379068 515.290779 \n",
       "L 507.990638 510.311627 \n",
       "L 512.602208 533.566219 \n",
       "L 517.213778 536.108219 \n",
       "L 521.825349 520.59554 \n",
       "L 526.436919 513.613003 \n",
       "L 531.048489 527.872169 \n",
       "L 535.660059 521.773753 \n",
       "L 540.27163 525.865199 \n",
       "L 544.8832 526.150183 \n",
       "L 549.49477 522.077569 \n",
       "L 554.10634 529.136582 \n",
       "L 558.717911 530.55216 \n",
       "L 563.329481 527.545654 \n",
       "L 567.941051 527.487528 \n",
       "\" clip-path=\"url(#p66fd2ceb4e)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 2; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 35.304688 561.6 \n",
       "L 35.304688 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 593.304688 561.6 \n",
       "L 593.304688 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 35.304688 561.6 \n",
       "L 593.304688 561.6 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 35.304688 7.2 \n",
       "L 593.304688 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 506.046875 44.55625 \n",
       "L 586.304688 44.55625 \n",
       "Q 588.304688 44.55625 588.304688 42.55625 \n",
       "L 588.304688 14.2 \n",
       "Q 588.304688 12.2 586.304688 12.2 \n",
       "L 506.046875 12.2 \n",
       "Q 504.046875 12.2 504.046875 14.2 \n",
       "L 504.046875 42.55625 \n",
       "Q 504.046875 44.55625 506.046875 44.55625 \n",
       "z\n",
       "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_17\">\n",
       "     <path d=\"M 508.046875 20.298438 \n",
       "L 518.046875 20.298438 \n",
       "L 528.046875 20.298438 \n",
       "\" style=\"fill: none; stroke: #1f77b4; stroke-width: 2; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_15\">\n",
       "     <!-- DATA loss -->\n",
       "     <g transform=\"translate(536.046875 23.798438) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-44\" d=\"M 1259 4147 \n",
       "L 1259 519 \n",
       "L 2022 519 \n",
       "Q 2988 519 3436 956 \n",
       "Q 3884 1394 3884 2338 \n",
       "Q 3884 3275 3436 3711 \n",
       "Q 2988 4147 2022 4147 \n",
       "L 1259 4147 \n",
       "z\n",
       "M 628 4666 \n",
       "L 1925 4666 \n",
       "Q 3281 4666 3915 4102 \n",
       "Q 4550 3538 4550 2338 \n",
       "Q 4550 1131 3912 565 \n",
       "Q 3275 0 1925 0 \n",
       "L 628 0 \n",
       "L 628 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-41\" d=\"M 2188 4044 \n",
       "L 1331 1722 \n",
       "L 3047 1722 \n",
       "L 2188 4044 \n",
       "z\n",
       "M 1831 4666 \n",
       "L 2547 4666 \n",
       "L 4325 0 \n",
       "L 3669 0 \n",
       "L 3244 1197 \n",
       "L 1141 1197 \n",
       "L 716 0 \n",
       "L 50 0 \n",
       "L 1831 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-54\" d=\"M -19 4666 \n",
       "L 3928 4666 \n",
       "L 3928 4134 \n",
       "L 2272 4134 \n",
       "L 2272 0 \n",
       "L 1638 0 \n",
       "L 1638 4134 \n",
       "L -19 4134 \n",
       "L -19 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-44\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-41\" x=\"75.251953\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-54\" x=\"135.910156\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-41\" x=\"189.244141\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" x=\"257.652344\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" x=\"289.439453\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"317.222656\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"378.404297\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"430.503906\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_18\">\n",
       "     <path d=\"M 508.046875 34.976563 \n",
       "L 518.046875 34.976563 \n",
       "L 528.046875 34.976563 \n",
       "\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 2; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_16\">\n",
       "     <!-- val -->\n",
       "     <g transform=\"translate(536.046875 38.476563) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-76\" d=\"M 191 3500 \n",
       "L 800 3500 \n",
       "L 1894 563 \n",
       "L 2988 3500 \n",
       "L 3597 3500 \n",
       "L 2284 0 \n",
       "L 1503 0 \n",
       "L 191 3500 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-76\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p66fd2ceb4e\">\n",
       "   <rect x=\"35.304688\" y=\"7.2\" width=\"558\" height=\"554.4\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowest Loss: -42.270813941955566\n"
     ]
    }
   ],
   "source": [
    "# TRAINING DATA\n",
    "loss_hist, val_hist, full_loss_hist, full_val_hist = train(training_data_DATA, DATA_model, val = True, val_data = val_data_DATA, num_epochs = 2, compact_num = 20)\n",
    "plot_loss(loss_hist, label = \"DATA loss\", plot_val = True, val_loss_hist = val_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798ec245-fd43-4feb-88b1-ba11f9226494",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 140/140 [00:02<00:00, 50.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC average loss: -38.01020431518555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 140/140 [00:02<00:00, 50.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA average loss: -40.962493896484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing MC\n",
    "test(testing_data_MC, MC_model, data_type = \"MC\")\n",
    "# Testing DATA\n",
    "test(testing_data_DATA, DATA_model, data_type = \"DATA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf7c202-e791-4a26-9964-c2196f1a6951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 140/140 [00:02<00:00, 49.09it/s]\n",
      "100%|██████████| 140/140 [00:02<00:00, 49.46it/s]\n"
     ]
    }
   ],
   "source": [
    "transformed_latent_MC = transform(testing_data_MC, MC_model)\n",
    "transformed_latent_DATA = transform(testing_data_DATA, DATA_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a980dc-1d2b-47d8-8423-28839cb26404",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1120/1120 [00:23<00:00, 48.36it/s]\n",
      "100%|██████████| 1120/1120 [00:23<00:00, 47.62it/s]\n",
      "100%|██████████| 1166/1166 [00:21<00:00, 54.22it/s]\n",
      "100%|██████████| 1166/1166 [00:21<00:00, 53.34it/s]\n"
     ]
    }
   ],
   "source": [
    "transformed_latent_train_MC = transform(training_data_MC, MC_model)\n",
    "transformed_latent_train_DATA = transform(training_data_DATA, DATA_model)\n",
    "transformed_latent_val_MC = transform(val_data_MC, MC_model)\n",
    "transformed_latent_val_DATA = transform(val_data_DATA, DATA_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead1efa8-deba-48d7-867f-8c82d3fcc8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From above plotting: <transformed_latent_DATA> is the tensor with normalized DATA\n",
    "# Now need to transform it back to MC version of latent space\n",
    "transformed_latent_DATA_obj = Latent_data(transformed_latent_DATA,testing_data_DATA.labels)\n",
    "transformed_latent_DATA_obj.set_batch_size(100)\n",
    "transformed_latent_MC_obj = Latent_data(transformed_latent_MC,testing_data_MC.labels)\n",
    "transformed_latent_MC_obj.set_batch_size(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29729091-0c85-46bc-a4a2-2ffc45c32e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_latent_train_DATA_obj = Latent_data(transformed_latent_train_DATA,training_data_DATA.labels)\n",
    "transformed_latent_train_DATA_obj.set_batch_size(100)\n",
    "transformed_latent_train_MC_obj = Latent_data(transformed_latent_train_MC,training_data_MC.labels)\n",
    "transformed_latent_train_MC_obj.set_batch_size(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ceca85a-1ffe-4b4f-a340-f916d009b085",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_latent_val_DATA_obj = Latent_data(transformed_latent_val_DATA,val_data_DATA.labels)\n",
    "transformed_latent_val_MC_obj = Latent_data(transformed_latent_val_MC,val_data_MC.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940369f3-032b-41a5-9388-173deb56a29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 140/140 [00:02<00:00, 50.44it/s]\n"
     ]
    }
   ],
   "source": [
    "full_pass_DATA = transform(transformed_latent_DATA_obj, MC_model, reverse = False)\n",
    "full_pass_DATA_obj = Latent_data(full_pass_DATA, testing_data_DATA.labels)\n",
    "full_pass_DATA_obj.set_batch_size(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736e60a8-a31c-4ab8-ba68-cc8e52e9ec85",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc9fb4d-fd8d-4210-ad28-31f4833c2ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NFClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Classifier for normalized tensors\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=71, num_classes=2, hidden_dim = 256, num_layers = 5):\n",
    "        super(NFClassifier, self).__init__()\n",
    "        self.layer = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            if(i == 0):\n",
    "                self.layer.append(\n",
    "                nn.Linear(input_size, hidden_dim)\n",
    "                )\n",
    "                self.layer.append(\n",
    "                    nn.ReLU(inplace=True)\n",
    "                )\n",
    "            elif(i == num_layers - 1):\n",
    "                self.layer.append(\n",
    "                nn.Linear(hidden_dim, num_classes)\n",
    "                )\n",
    "            else:\n",
    "                self.layer.append(\n",
    "                    nn.Linear(hidden_dim, hidden_dim)\n",
    "                )\n",
    "                self.layer.append(\n",
    "                    nn.ReLU(inplace=True)\n",
    "                )\n",
    "        self.name = \"Classifier\"\n",
    "        \n",
    "    def forward(self, h):\n",
    "        c = self.layer(h)\n",
    "        return c\n",
    "    \n",
    "    # @property\n",
    "    def name(self):\n",
    "        \"\"\"\n",
    "        Name of model.\n",
    "        \"\"\"\n",
    "        return self.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc2b254-c509-4e90-b54b-c04e5f356f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = NFClassifier().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeca52c0-bdd8-4553-97ff-e45306d01fe2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(classifier\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-4\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\n\u001b[1;32m      3\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_classifier\u001b[39m(train_data, classifier, criterion, optimizer, val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, val_data \u001b[38;5;241m=\u001b[39m val_data, num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      5\u001b[0m     loss_hist \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(val):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_data' is not defined"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=5e-4, weight_decay=1e-5)\n",
    "num_epochs = 6\n",
    "def train_classifier(train_data, classifier, criterion, optimizer, val = True, val_data = val_data, num_epochs = 1):\n",
    "    loss_hist = np.array([])\n",
    "    if(val):\n",
    "        val_data.set_batch_size(int(np.floor(val_data.num_events / train_data.max_iter)))\n",
    "        val_loss_hist = np.array([])\n",
    "    for i in range(num_epochs):\n",
    "        epoch_hist = np.array([])\n",
    "        val_epoch_hist = np.array([])\n",
    "        with tqdm(total=train_data.max_iter, position=0, leave=True) as pbar:\n",
    "            for it in tqdm(range(train_data.max_iter), position = 0, leave=True):\n",
    "                optimizer.zero_grad()\n",
    "                #randomly sample the latent space\n",
    "                samples, labels = train_data.sample(iteration = it, _give_labels = True)\n",
    "                samples = samples.to(device)\n",
    "                labels = (labels.type(torch.LongTensor)).to(device)\n",
    "                # forward + backward + optimize\n",
    "                outputs = classifier(samples)\n",
    "                loss = criterion(outputs, labels[:,0])\n",
    "                # Do backprop and optimizer step\n",
    "                if ~(torch.isnan(loss) | torch.isinf(loss)):\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                # Log loss\n",
    "                if~(torch.isnan(loss)):\n",
    "                    epoch_hist = np.append(epoch_hist, loss.to('cpu').data.numpy())\n",
    "                if(val):\n",
    "                    #validation\n",
    "                    val_samples, val_labels = val_data.sample(iteration = it, _give_labels = True)\n",
    "                    val_samples = val_samples.to(device)\n",
    "                    val_labels = (val_labels.type(torch.LongTensor)).to(device)\n",
    "                    val_outputs = classifier(val_samples)\n",
    "                    val_loss = criterion(val_outputs, val_labels[:,0])\n",
    "                    val_epoch_hist = np.append(val_epoch_hist, val_loss.to('cpu').data.numpy())\n",
    "        loss_hist = np.append(loss_hist, epoch_hist.mean())\n",
    "        if(val):\n",
    "            val_loss_hist = np.append(val_loss_hist, val_epoch_hist.mean())\n",
    "\n",
    "    print('Finished Training')\n",
    "    if(val):\n",
    "        return loss_hist, val_loss_hist\n",
    "    else:\n",
    "        return loss_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c52f07-7399-4936-bbbd-0f98b9f0657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_hist, val_loss_hist = train_classifier(train_data, classifier, criterion, optimizer, val = True, val_data = val_data, num_epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c54335a-bc88-45a6-8dd4-50dc88a5ad89",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(loss_hist, plot_val =True, val_loss_hist = val_loss_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c933e4a-1bf4-467c-84b0-eef4244a3c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = torch.empty(testing_data_MC.num_events,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c34115d-a979-4a15-a412-8e5eeee4f5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "def test_classifier_MC(test_data, classifier):\n",
    "    outputs = torch.empty(test_data.num_events,2)    \n",
    "    with tqdm(total=test_data.max_iter, position=0, leave=True) as pbar:\n",
    "        for it in tqdm(range(test_data.max_iter), position = 0, leave=True):\n",
    "            #randomly sample the latent space\n",
    "            samples, labels = test_data.sample(iteration = it, _give_labels = True)\n",
    "            samples = samples.to(device)\n",
    "            # forward + backward + optimize\n",
    "            output_batch = classifier(samples)\n",
    "            for i in range(test_data.batch_size):\n",
    "                outputs[it*test_data.batch_size + i] = output_batch[i]\n",
    "    test_Y     = test_data.labels.clone().detach().float().view(-1, 1).to(\"cpu\")\n",
    "    probs_Y = torch.softmax(outputs, 1)\n",
    "    argmax_Y = torch.max(probs_Y, 1)[1].view(-1,1)\n",
    "    test_acc = (test_Y == argmax_Y.float()).sum().item() / len(test_Y)\n",
    "    print(f\"Accuracy: {test_acc * 100}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdd7f51-63c3-4997-bf43-a573003f6863",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "\n",
    "\n",
    "with tqdm(total=testing_data_MC.max_iter, position=0, leave=True) as pbar:\n",
    "    for it in tqdm(range(testing_data_MC.max_iter), position = 0, leave=True):\n",
    "        #randomly sample the latent space\n",
    "        samples, labels = testing_data_MC.sample(iteration = it, _give_labels = True)\n",
    "        samples = samples.to(device)\n",
    "        # forward + backward + optimize\n",
    "        output_batch = classifier(samples)\n",
    "        for i in range(testing_data_MC.batch_size):\n",
    "            outputs[it*testing_data_MC.batch_size + i] = output_batch[i]\n",
    "print('Finished Running')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e877ba-f00f-4186-8f9d-0aaa025c4427",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Y     = testing_data_MC.labels.clone().detach().float().view(-1, 1).to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90700d43-1f05-4de7-abdf-8cfe347c1b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_Y = torch.softmax(outputs, 1)\n",
    "argmax_Y = torch.max(probs_Y, 1)[1].view(-1,1)\n",
    "test_acc = (test_Y == argmax_Y.float()).sum().item() / len(test_Y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001e4b99-fa4b-4704-97dc-580520e9539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01210034-1f5f-4532-9d79-6facaa413ef5",
   "metadata": {},
   "source": [
    "## Testing Classifier on DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7855c878-c171-41c8-9f15-5174841ef79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier_data(test_data, classifier):\n",
    "    outputs_data = torch.empty(test_data.num_events,2)\n",
    "    #Converting normalized DATA to classifier output\n",
    "    with tqdm(total=test_data.max_iter, position=0, leave=True) as pbar:\n",
    "        for it in tqdm(range(test_data.max_iter), position = 0, leave=True):\n",
    "            #randomly sample the latent space\n",
    "            samples, labels = test_data.sample(iteration = it, _give_labels = True)\n",
    "            samples = samples.to(device)\n",
    "            # forward + backward + optimize\n",
    "            output_batch = classifier(samples)\n",
    "            for i in range(test_data.batch_size):\n",
    "                outputs_data[it*test_data.batch_size + i] = output_batch[i]\n",
    "    probs_data = torch.softmax(outputs_data, 1)\n",
    "    argmax_Y = torch.max(probs_data, 1)[1].view(-1,1)\n",
    "    return argmax_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676b89f7-8028-42ed-9572-4db5057e7545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent_data = training_data_MC\n",
    "latent_data = full_pass_DATA_obj\n",
    "outputs_data = torch.empty(latent_data.num_events,2)\n",
    "\n",
    "#Converting normalized DATA to classifier output\n",
    "with tqdm(total=latent_data.max_iter, position=0, leave=True) as pbar:\n",
    "    for it in tqdm(range(latent_data.max_iter), position = 0, leave=True):\n",
    "        #randomly sample the latent space\n",
    "        samples, labels = latent_data.sample(iteration = it, _give_labels = True)\n",
    "        samples = samples.to(device)\n",
    "        # forward + backward + optimize\n",
    "        output_batch = classifier(samples)\n",
    "        for i in range(latent_data.batch_size):\n",
    "            outputs_data[it*latent_data.batch_size + i] = output_batch[i]\n",
    "print('Finished Running')\n",
    "probs_data = torch.softmax(outputs_data, 1)\n",
    "argmax_Y = torch.max(probs_data, 1)[1].view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f316cdd-7669-4487-9436-6e0a1a35e104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classified(masses, classes, label = \"none\",save = False, save_loc = \"plots/default.jpeg\", figsize = (18,4), bins = 100):\n",
    "    num_total = int(classes.size()[0])\n",
    "    num_signal = int(classes.sum())\n",
    "    signal = np.zeros(num_signal)\n",
    "    bg = np.zeros(num_total-num_signal)\n",
    "    bg_count, signal_count = 0, 0\n",
    "    for i in range(num_total):\n",
    "        if classes[i]:\n",
    "            signal[signal_count] = Lambda_masses[i]\n",
    "            signal_count+= 1\n",
    "        else:\n",
    "            bg[bg_count] = Lambda_masses[i]\n",
    "            bg_count += 1\n",
    "    histos, (h1,h2,h3) = plt.subplots(1,3, figsize = figsize)\n",
    "    h1.hist(signal, bins = bins, label = \"signal\", color = \"b\")\n",
    "    h2.hist(bg, bins = bins, label = \"background\", color = \"xkcd:orange\")\n",
    "    if(label != \"none\"):\n",
    "        h3.hist(training_data_MC.mass, bins = bins, label = label)\n",
    "    else:\n",
    "        h3.hist(training_data_MC.mass, bins = bins)\n",
    "\n",
    "    leg = histos.legend(title = \"Key\")\n",
    "    histos.show()\n",
    "    if(save):\n",
    "        histos.savefig(save_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c689612-8aeb-4221-92f4-4eb968bea9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_total = int(argmax_Y.size()[0])\n",
    "num_signal = int(argmax_Y.sum())\n",
    "signal = np.zeros(num_signal)\n",
    "bg = np.zeros(num_total-num_signal)\n",
    "bg_count, signal_count = 0, 0\n",
    "Lambda_masses = training_data_MC.mass\n",
    "for i in range(num_total):\n",
    "    if argmax_Y[i]:\n",
    "        signal[signal_count] = Lambda_masses[i]\n",
    "        signal_count+= 1\n",
    "    else:\n",
    "        bg[bg_count] = Lambda_masses[i]\n",
    "        bg_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e79b38-d2de-4707-ac27-2ca09dc67e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "histos, (h1,h2,h3) = plt.subplots(1,3, figsize = (18,4))\n",
    "h1.hist(signal, bins = 100, label = \"signal\", color = \"b\")\n",
    "h2.hist(bg, bins = 100, label = \"background\", color = \"xkcd:orange\")\n",
    "h3.hist(training_data_MC.mass, bins = 100, label = \"full spectrum, data\")\n",
    "\n",
    "leg = histos.legend(title = \"Key\")\n",
    "histos.show()\n",
    "# histos.savefig(\"plots/sig_vs_bg_full_pass_data.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25ca0b3-e8ab-480b-813f-945c22110b62",
   "metadata": {},
   "source": [
    "#### Checking what MC truth looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "db0752ff-3833-403e-98d2-6774f2e44dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "argmax_Y = transformed_latent_MC_obj.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6745db86-d5a0-4cad-9e02-f74ca5cc32a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_total = int(argmax_Y.size()[0])\n",
    "num_signal = int(argmax_Y.sum())\n",
    "signal = np.zeros(num_signal)\n",
    "bg = np.zeros(num_total-num_signal)\n",
    "bg_count, signal_count = 0, 0\n",
    "Lambda_masses = testing_data_MC.mass\n",
    "for i in range(num_total):\n",
    "    if argmax_Y[i]:\n",
    "        signal[signal_count] = Lambda_masses[i]\n",
    "        signal_count+= 1\n",
    "    else:\n",
    "        bg[bg_count] = Lambda_masses[i]\n",
    "        bg_count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
