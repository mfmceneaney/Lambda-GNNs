{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5a2b256-3b63-430a-bb7d-f43e4bcaec0d",
   "metadata": {},
   "source": [
    "# Notebook for testing how distortions change in Normalizing Flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e889b5c3-6043-422b-994a-63436ed26189",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/group/vossenlab/rck32/miniconda3/envs/venv/lib/python3.11/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/hpc/group/vossenlab/rck32/miniconda3/envs/venv/lib/python3.11/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/hpc/group/vossenlab/rck32/miniconda3/envs/venv/lib/python3.11/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/hpc/group/vossenlab/rck32/miniconda3/envs/venv/lib/python3.11/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "2024-01-22 17:32:49.719552: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-22 17:32:59.775162: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import normflows as nf\n",
    "from normflows import flows\n",
    "## Standard libraries\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import numpy as np \n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as tdata\n",
    "import torch.optim as optim\n",
    "\n",
    "import dgl #NOTE: for dgl.batch and dgl.unbatch\n",
    "from dgl import save_graphs, load_graphs\n",
    "from dgl.data import DGLDataset\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from dgl.data.utils import save_info, load_info, Subset\n",
    "\n",
    "import umap\n",
    "reducer = umap.UMAP();\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Fetching the device that will be used throughout this notebook\n",
    "device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda:0\")\n",
    "print(\"Using device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2c2e4f0-72ff-4a37-a9d5-73ec9e8ac6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "#custom imports\n",
    "from utils import load_graph_dataset, train, evaluate, GraphDataset, get_graph_dataset_info\n",
    "from models import GIN, HeteroGIN\n",
    "from NF_utils import Latent_data, create_latent_data, get_masked_affine, transform, train,plot_loss, test,plot_9_histos, plot_UMAP_sidebyside,plot_UMAP_overlay, transform_double\n",
    "from GAN_utils import GAN_Input#, GAN_Input_double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a02ccf8-30b1-472e-9a36-29b2d39da96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import default_rng\n",
    "rng = default_rng()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a973c3d3-3048-4397-92ff-f70e26c316be",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''                                              '''\n",
    "'''     SETTING UP LATENT SPACE REPRESENTATION   '''\n",
    "'''                                              '''\n",
    "\n",
    "# Data and MC both have the same prefix\n",
    "prefix = \"/hpc/group/vossenlab/mfm45/.dgl/\"\n",
    "\n",
    "# MC inside Lambda_train_matched_jobs_outbending_cache_bg50nA_7_28_22__pT_phi_theta_beta_chi2_pid_status__Normalized\n",
    "MCdataset = \"Lambda_train_matched_jobs_outbending_cache_bg50nA_7_28_22__pT_phi_theta_beta_chi2_pid_status__Normalized\"\n",
    "\n",
    "# Data inside data_jobs_rga_fall2018_7_28_22__pT_phi_theta_beta_chi2_pid_status__Normalized\n",
    "DATAdataset = \"data_jobs_rga_fall2018_7_28_22__pT_phi_theta_beta_chi2_pid_status__Normalized\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a089b915-a9b6-4394-ac20-4a47f59e623b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 100\n",
    "MC_Graphs = GraphDataset(prefix+MCdataset)\n",
    "\n",
    "#pid dictionary:\n",
    "pid_dict = {\n",
    "    0 : \"photon\",\n",
    "    1 : \"electron\",\n",
    "    -1 : \"positron\",\n",
    "    0.8 : \"proton\",\n",
    "    -0.8 : \"anti-proton\",\n",
    "    0.5 : \"neutron\",\n",
    "    -0.5 : \"anti-neutron\",\n",
    "    0.1 : \"pi0\",\n",
    "    0.6 : \"pi+\",\n",
    "    -0.6 : \"pi-\",\n",
    "    0.3 : \"K0\",\n",
    "    0.4 : \"K+\",\n",
    "    -0.4 : \"K-\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d75076d3-7c11-4e64-a131-b89622d4b4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distorted_inputs = GAN_Input_double(MC_Graphs, distortion_range = (-0.1,0.1), num_features = 20, num_sample_features = 12)\n",
    "#inputs = GAN_Input_double(MC_Graphs, distortion_range = (-0.1,0.1), distort = True, num_features = 20, num_sample_features = 12)\n",
    "inputs = GAN_Input(MC_Graphs, distortion_range = (-0.1,0.1), distort = True, num_features = 14, num_sample_features = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "658e9ecb-48cf-47a8-861b-f941875aae59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([130669, 20])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62e8aced-2867-4dd5-9ba1-498d488567e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([130669, 15])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.data[:,5:].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e82d287-f18d-473d-b243-024446eb15a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 1057/1306 [01:44<00:24, 10.16it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m MC_model \u001b[38;5;241m=\u001b[39m masked_affine_model_MC\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# TRAINING MC\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m MC_loss, MC_full_loss \u001b[38;5;241m=\u001b[39m train(inputs, MC_model, distorted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m,compact_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     10\u001b[0m plot_loss(MC_loss, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMC loss\u001b[39m\u001b[38;5;124m\"\u001b[39m,save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, save_loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplots/Distortion/NF_loss/Jan_22_MC.jpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/hpc/group/vossenlab/rck32/Lambda-GNNs/NF_utils.py:441\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(in_data, model, val, val_data, num_epochs, compact_num, distorted, show_progress, lr)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    440\u001b[0m     samples \u001b[38;5;241m=\u001b[39m in_data\u001b[38;5;241m.\u001b[39msample(iteration \u001b[38;5;241m=\u001b[39m it)\n\u001b[0;32m--> 441\u001b[0m samples \u001b[38;5;241m=\u001b[39m samples\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    442\u001b[0m loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward_kld(samples)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;66;03m# Do backprop and optimizer step\u001b[39;00m\n",
      "File \u001b[0;32m/hpc/group/vossenlab/rck32/miniconda3/envs/venv/lib/python3.11/site-packages/normflows/core.py:99\u001b[0m, in \u001b[0;36mNormalizingFlow.forward_kld\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     97\u001b[0m z \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflows) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 99\u001b[0m     z, log_det \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflows[i]\u001b[38;5;241m.\u001b[39minverse(z)\n\u001b[1;32m    100\u001b[0m     log_q \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m log_det\n\u001b[1;32m    101\u001b[0m log_q \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq0\u001b[38;5;241m.\u001b[39mlog_prob(z)\n",
      "File \u001b[0;32m/hpc/group/vossenlab/rck32/miniconda3/envs/venv/lib/python3.11/site-packages/normflows/flows/affine/coupling.py:222\u001b[0m, in \u001b[0;36mMaskedAffineFlow.inverse\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minverse\u001b[39m(\u001b[38;5;28mself\u001b[39m, z):\n\u001b[1;32m    221\u001b[0m     z_masked \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb \u001b[38;5;241m*\u001b[39m z\n\u001b[0;32m--> 222\u001b[0m     scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ms(z_masked)\n\u001b[1;32m    223\u001b[0m     nan \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39mnan, dtype\u001b[38;5;241m=\u001b[39mz\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mz\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    224\u001b[0m     scale \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(torch\u001b[38;5;241m.\u001b[39misfinite(scale), scale, nan)\n",
      "File \u001b[0;32m/hpc/group/vossenlab/rck32/miniconda3/envs/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/hpc/group/vossenlab/rck32/miniconda3/envs/venv/lib/python3.11/site-packages/normflows/nets/mlp.py:58\u001b[0m, in \u001b[0;36mMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet(x)\n",
      "File \u001b[0;32m/hpc/group/vossenlab/rck32/miniconda3/envs/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/hpc/group/vossenlab/rck32/miniconda3/envs/venv/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/hpc/group/vossenlab/rck32/miniconda3/envs/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/hpc/group/vossenlab/rck32/miniconda3/envs/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# SETTING UP MC MODEL\n",
    "\n",
    "masked_affine_flows_train_MC = get_masked_affine(latent_dim = 6,hidden_dim = 24,num_layers = 60, alternate_mask = False)\n",
    "distribution_MC = nf.distributions.DiagGaussian(inputs.num_sample_features, trainable = False)\n",
    "masked_affine_model_MC = nf.NormalizingFlow(q0=distribution_MC, flows=masked_affine_flows_train_MC)\n",
    "MC_model = masked_affine_model_MC.to(device)\n",
    "\n",
    "# TRAINING MC\n",
    "MC_loss, MC_full_loss = train(inputs, MC_model, distorted = False, num_epochs = 4,compact_num = 10)\n",
    "plot_loss(MC_loss, label = \"MC loss\",save = True, save_loc = \"plots/Distortion/NF_loss/Jan_22_MC.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710053f9-71c4-4238-84d5-9d973f75c031",
   "metadata": {},
   "outputs": [],
   "source": [
    "MC_model.save(\"models/NF_distort/no_distort/Jan_22/MC.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfc1d25-725e-449a-b370-e8d4b7f8e765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# masked_affine_flows_train_MC = get_masked_affine(latent_dim = 12,hidden_dim = 36,num_layers = 60)\n",
    "# distribution_MC = nf.distributions.DiagGaussian(inputs.num_sample_features, trainable = False)\n",
    "# masked_affine_model_MC = nf.NormalizingFlow(q0=distribution_MC, flows=masked_affine_flows_train_MC)\n",
    "# masked_affine_model_MC.load(\"models/NF_distort/MC_july_17_double_features.pth\")\n",
    "# MC_model = masked_affine_model_MC.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c553a283-14a7-41a2-8c73-8aa528507ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTING UP DATA MODEL\n",
    "\n",
    "masked_affine_flows_train_distort = get_masked_affine(latent_dim = 6, hidden_dim = 24, num_layers = 60, alternate_mask = False)\n",
    "distribution_distort = nf.distributions.DiagGaussian(inputs.num_sample_features, trainable = False)\n",
    "masked_affine_model_distort = nf.NormalizingFlow(q0=distribution_distort, flows=masked_affine_flows_train_distort)\n",
    "distort_model = masked_affine_model_distort.to(device)\n",
    "\n",
    "# TRAINING Distorted\n",
    "distort_loss, distort_full_loss = train(inputs, distort_model, distorted = True, num_epochs = 2, compact_num = 10)\n",
    "plot_loss(distort_loss, label = \"Distorted loss\",save = True, save_loc = \"plots/Distortion/NF_loss/Jan_22_MC.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f40de8-8863-46cf-9408-95d5bcc481d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "distort_model.save(\"models/NF_distort/distort/Jan_22/Data_0_1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbb857d-1701-4e31-bc40-669c4a6c271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# masked_affine_flows_train_distort = get_masked_affine(latent_dim = 12, hidden_dim = 36, num_layers = 60)\n",
    "# distribution_distort = nf.distributions.DiagGaussian(inputs.num_sample_features, trainable = False)\n",
    "# masked_affine_model_distort = nf.NormalizingFlow(q0=distribution_distort, flows=masked_affine_flows_train_distort)\n",
    "# masked_affine_model_distort.load(\"models/NF_distort/distort_july_16_double_features.pth\")\n",
    "# distort_model = masked_affine_model_distort.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96bfa06-26fa-4c2e-8241-604d1db42a2d",
   "metadata": {},
   "source": [
    "# Testing MC and DATA models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcbba6b-73fb-4519-81c4-70986a3e10e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing MC\n",
    "test(inputs, MC_model, data_type = \"MC\")\n",
    "# Testing DATA\n",
    "test(distorted_inputs, distort_model, data_type = \"MC distorted\", distorted = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496e0dde-9c97-4351-a4b5-7e3f66117725",
   "metadata": {},
   "source": [
    "# Plotting sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c599af83-1bf1-4fe3-8db6-77ab84ae3f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized_MC = transform(inputs, MC_model)\n",
    "normalized_distorted = transform_double(inputs, distort_model, distorted = True)\n",
    "\n",
    "normalized_distorted_obj = Latent_data(normalized_distorted, torch.empty([]))\n",
    "normalized_distorted_obj.set_batch_size(100)\n",
    "full_pass_distorted = transform_double(normalized_distorted_obj, MC_model, reverse = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761a8a11-b3d3-4144-a617-8a8f92c1c2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fpd = torch.clone(full_pass_distorted)\n",
    "plot_distorted_data = torch.clone(inputs.distorted_features)\n",
    "plot_train_data = torch.clone(inputs.data)\n",
    "for i in range(len(plot_fpd)):\n",
    "    for j in range(12):\n",
    "        if(np.isnan(plot_fpd[i,j])):\n",
    "            plot_fpd[i,0] = 99999\n",
    "            plot_train_data[i,0] = 99999\n",
    "            plot_distorted_data[i,0] = 99999\n",
    "            break\n",
    "plot_fpd = plot_fpd[plot_fpd[:,0] != 99999]\n",
    "plot_distorted_data = plot_distorted_data[plot_distorted_data[:,0] != 99999]\n",
    "plot_train_data = plot_train_data[plot_train_data[:,0] != 99999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a736e72d-a53f-4512-96c9-7b106c83a65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(full_pass_distorted) - len(plot_fpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19f6c08-9ae8-4bcb-afdc-447014eb153e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax11,ax12,ax13),(ax21,ax22,ax23),(his1,his2,his3)) = plt.subplots(3,3,figsize = (12,12))\n",
    "axlist = [ax11,ax12,ax13,ax21,ax22,ax23]\n",
    "names = [\"Proton pT\", \"Proton phi\", \"Proton theta\", \"Pion pT\", \"Pion phi\", \"Pion theta\"]\n",
    "fig.suptitle(\"Distorted vs fullpass with +/-0.04 distortion\")\n",
    "for i in range(6):\n",
    "    x1 = torch.Tensor.numpy(plot_distorted_data[:,i])\n",
    "    y1 = torch.Tensor.numpy(plot_fpd[:,i])\n",
    "    axlist[i].hist2d(x1,y1,bins = 200, cmap = plt.cm.jet)\n",
    "    axlist[i].set_xlabel(names[i])\n",
    "ax11.set_xlim(-1,1)\n",
    "ax11.set_ylim(-1,1)\n",
    "his1.hist(inputs.data[:,0], bins = 100,color = 'r')\n",
    "his1.set_xlabel(\"MC\")\n",
    "his1.set_xlim(-1,1)\n",
    "his2.hist(inputs.distorted_features[:,0], bins = 100,color = 'b')\n",
    "his2.set_xlabel(\"distorted\")\n",
    "his2.set_xlim(-1,1)\n",
    "his3.hist(full_pass_distorted[:,0], bins = 100,color = 'g')\n",
    "his3.set_xlabel(\"fullpass\")\n",
    "his3.set_xlim(-1,1)\n",
    "fig.show()\n",
    "fig.savefig(\"plots/NF_double/distorted_MC_vs_fullpass_july_18_0_04_notebook.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7715ec05-f7ec-4c73-9858-6f1a96b8e87b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
