{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e526d465-1839-4126-aa86-68b93e959ad9",
   "metadata": {},
   "source": [
    "# Optimizing the NF model using optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ca697cc-ec91-4c14-8e85-ea0c4497be39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/group/vossenlab/rck32/miniconda3/envs/venv/lib/python3.11/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/hpc/group/vossenlab/rck32/miniconda3/envs/venv/lib/python3.11/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/hpc/group/vossenlab/rck32/miniconda3/envs/venv/lib/python3.11/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/hpc/group/vossenlab/rck32/miniconda3/envs/venv/lib/python3.11/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "2023-06-29 22:47:13.227729: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-29 22:47:16.094516: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from NF_utils import Latent_data\n",
    "#custom imports\n",
    "from utils import load_graph_dataset, train, evaluate, GraphDataset, get_graph_dataset_info\n",
    "from models import GIN, HeteroGIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34774b22-37fe-46f3-8dc6-4da4c50ef2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import normflows as nf\n",
    "from normflows import flows\n",
    "## Standard libraries\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "\n",
    "import dgl #NOTE: for dgl.batch and dgl.unbatch\n",
    "from dgl import save_graphs, load_graphs\n",
    "from dgl.data import DGLDataset\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from dgl.data.utils import save_info, load_info, Subset\n",
    "\n",
    "import umap\n",
    "reducer = umap.UMAP();\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "addab7c2-00bc-4068-ab4d-b07292e96594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DEVICE cuda:0\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda:0\")\n",
    "# DEVICE = torch.device(\"cpu\")\n",
    "print(\"Using DEVICE\", DEVICE)\n",
    "\n",
    "BATCHSIZE = 100\n",
    "CLASSES = 2\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3b0f820-4747-4d58-9c41-b4b87a604023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data and MC both have the same prefix\n",
    "prefix = \"/hpc/group/vossenlab/mfm45/.dgl/\"\n",
    "\n",
    "# MC inside Lambda_train_matched_jobs_outbending_cache_bg50nA_7_28_22__pT_phi_theta_beta_chi2_pid_status__Normalized\n",
    "MCdataset = \"Lambda_train_matched_jobs_outbending_cache_bg50nA_7_28_22__pT_phi_theta_beta_chi2_pid_status__Normalized\"\n",
    "\n",
    "# Data inside data_jobs_rga_fall2018_7_28_22__pT_phi_theta_beta_chi2_pid_status__Normalized\n",
    "DATAdataset = \"data_jobs_rga_fall2018_7_28_22__pT_phi_theta_beta_chi2_pid_status__Normalized\"\n",
    "max_events = 1e5\n",
    "split = 0.1\n",
    "nlayers = 2\n",
    "nmlp = 3\n",
    "hdim = 64\n",
    "nclasses, nfeatures, nfeatures_edge = get_graph_dataset_info(dataset=MCdataset, prefix=prefix)\n",
    "dropout = 0.8\n",
    "learn_eps = False\n",
    "batch = 256\n",
    "indices = None\n",
    "nworkers = 0\n",
    "npooling = \"max\"\n",
    "gpooling = \"max\"\n",
    "torch.manual_seed(0)\n",
    "\n",
    "#select model\n",
    "extractor = GIN(nlayers, nmlp, nfeatures,\n",
    "            hdim, nclasses, dropout, learn_eps, npooling, gpooling).to(DEVICE)\n",
    "extractor.load_state_dict(torch.load(\"logs/model_weights\",map_location=DEVICE))\n",
    "\n",
    "\n",
    "\n",
    "DATA_max_events = 249090\n",
    "MC_max_events = 141118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba212c81-1ddc-4ccb-a86b-917bae5430cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_latent_data(dataset_directory, extractor, prefix = \"/hpc/group/vossenlab/mfm45/.dgl/\", split = 0.8, max_events = 140000, num_samples = 250, mode = \"default\",shuffle = True):\n",
    "    val_split = (1 - split) / 2\n",
    "    if(mode == \"test\"):\n",
    "        data_range = range(int(split*max_events),int((val_split + split)*max_events))\n",
    "    elif(mode == \"train\"):\n",
    "        data_range = range(0, int(split*max_events))\n",
    "    elif(mode == \"val\"):\n",
    "        data_range = range(int((val_split + split)*max_events),max_events)\n",
    "    elif(mode == \"default\"):\n",
    "        print(f\"No mode given, defaulting to training\\n\")\n",
    "        data_range = range(0, int(split*max_events))\n",
    "    else:\n",
    "        raise Exception(\"Invalid mode: {mode}\\nPlease use either \\\"train,\\\" or \\\"test\\\" \", mode)\n",
    "    dataset = GraphDataset(prefix+dataset_directory)\n",
    "    dataset.load()\n",
    "    if(shuffle):\n",
    "        dataset.shuffle()\n",
    "    dataset = Subset(dataset,data_range)\n",
    "    dgl_batch = dgl.batch(dataset.dataset.graphs[dataset.indices.start:dataset.indices.stop])\n",
    "    labels = dataset.dataset.labels[dataset.indices.start:dataset.indices.stop,0].clone().detach().float().view(-1, 1)\n",
    "    mass = dataset.dataset.labels[dataset.indices.start:dataset.indices.stop,1].clone().detach().float()\n",
    "    dgl_batch = dgl_batch.to(DEVICE)\n",
    "    labels = labels.to(DEVICE)\n",
    "    latent = extractor.get_latent_repr(dgl_batch).detach().cpu()\n",
    "    latent_obj = Latent_data(latent,labels)\n",
    "    latent_obj.set_batch_size(num_samples)\n",
    "    latent_obj.set_mass(mass)\n",
    "    return latent_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c64853e-2c9e-4bbf-ad3a-d7316052a31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No mode given, defaulting to training\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/group/vossenlab/rck32/miniconda3/envs/venv/lib/python3.11/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No mode given, defaulting to training\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_samples = 100\n",
    "training_data_DATA = create_latent_data(DATAdataset, extractor,num_samples = num_samples, max_events = DATA_max_events)\n",
    "training_data_MC = create_latent_data(MCdataset, extractor,num_samples = num_samples, max_events = MC_max_events)\n",
    "\n",
    "testing_data_DATA = create_latent_data(DATAdataset, extractor, mode = \"test\",num_samples = num_samples, max_events = DATA_max_events)\n",
    "testing_data_MC = create_latent_data(MCdataset, extractor, mode = \"test\",num_samples = num_samples, max_events = MC_max_events)\n",
    "\n",
    "val_data_DATA = create_latent_data(DATAdataset, extractor, mode = \"val\",num_samples = num_samples, max_events = DATA_max_events)\n",
    "val_data_MC = create_latent_data(MCdataset, extractor, mode = \"val\",num_samples = num_samples, max_events = MC_max_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "015538f6-6585-4046-81c4-fa80ab154a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NF_model_optimize(trial):\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 24, 64)\n",
    "    #mask\n",
    "    b = torch.ones(71)\n",
    "    for i in range(b.size()[0]):\n",
    "        if i % 2 == 0:\n",
    "            b[i] = 0\n",
    "    masked_affine_flows = []\n",
    "    for i in range(num_layers):\n",
    "        s = nf.nets.MLP([71, 142, 142, 71])\n",
    "        t = nf.nets.MLP([71, 142, 142, 71])\n",
    "        if i % 2 == 0:\n",
    "            masked_affine_flows += [nf.flows.MaskedAffineFlow(b, t, s)]\n",
    "        else:\n",
    "            masked_affine_flows += [nf.flows.MaskedAffineFlow(1 - b, t, s)]\n",
    "    distribution = nf.distributions.DiagGaussian(training_data_DATA.latent_size, trainable = False)\n",
    "    masked_affine_model = nf.NormalizingFlow(q0=distribution, flows=masked_affine_flows)\n",
    "    return masked_affine_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "684d9d7c-12c5-4a57-ba9e-d4f561535346",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data = training_data_DATA\n",
    "val_data = val_data_DATA\n",
    "val_data.set_batch_size(int(np.floor(val_data.num_events / in_data.max_iter)))\n",
    "\n",
    "def objective(trial):\n",
    "    # Generate the optimizers.\n",
    "    model = NF_model_optimize(trial).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-5)\n",
    "    for epoch in range(1):\n",
    "        print(f\"starting epoch #{epoch}\")\n",
    "        with tqdm(total=in_data.max_iter, position=0, leave=True) as pbar:\n",
    "            for it in tqdm(range(in_data.max_iter), position = 0, leave=True):\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                #randomly sample the latent space\n",
    "                samples = in_data.sample(iteration = it)\n",
    "                samples = samples.to(DEVICE)\n",
    "                loss = model.forward_kld(samples)\n",
    "                # Do backprop and optimizer step\n",
    "                if ~(torch.isnan(loss) | torch.isinf(loss)):\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "        print(f\"starting val epoch #{epoch}\")\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with tqdm(total=in_data.max_iter, position=0, leave=True) as pbar:\n",
    "            for it in tqdm(range(in_data.max_iter), position = 0, leave=True):\n",
    "                val_samples = val_data.sample(iteration = it)\n",
    "                val_samples = val_samples.to(DEVICE)\n",
    "                val_loss += model.forward_kld(val_samples)\n",
    "        avg_loss = val_loss / in_data.max_iter\n",
    "        trial.report(avg_loss, epoch)\n",
    "        \n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "    return avg_loss         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63752adc-3489-44ab-9d77-33dce0a23ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-29 22:51:31,124] A new study created in memory with name: no-name-67eb7966-9b87-45b6-9de7-dea87dfc7f29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [02:00<00:00, 16.48it/s]\n",
      "  0%|          | 0/1992 [02:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting val epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [00:36<00:00, 54.44it/s]\n",
      "  0%|          | 0/1992 [00:36<?, ?it/s]\n",
      "[I 2023-06-29 22:54:08,813] Trial 0 finished with value: -37.29963302612305 and parameters: {'num_layers': 27}. Best is trial 0 with value: -37.29963302612305.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [01:36<00:00, 20.71it/s]\n",
      "  0%|          | 0/1992 [01:36<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting val epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [01:14<00:00, 26.61it/s]\n",
      "  0%|          | 0/1992 [01:14<?, ?it/s]\n",
      "[W 2023-06-29 22:57:02,364] Trial 1 failed with parameters: {'num_layers': 56} because of the following error: The value nan is not acceptable..\n",
      "[W 2023-06-29 22:57:02,429] Trial 1 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [03:14<00:00, 10.24it/s]\n",
      "  0%|          | 0/1992 [03:14<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting val epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [01:01<00:00, 32.14it/s]\n",
      "  0%|          | 0/1992 [01:01<?, ?it/s]\n",
      "[I 2023-06-29 23:01:23,750] Trial 2 finished with value: -37.61505126953125 and parameters: {'num_layers': 47}. Best is trial 2 with value: -37.61505126953125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [02:53<00:00, 11.45it/s]\n",
      "  0%|          | 0/1992 [02:53<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting val epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [00:50<00:00, 39.79it/s]\n",
      "  0%|          | 0/1992 [00:50<?, ?it/s]\n",
      "[I 2023-06-29 23:05:11,522] Trial 3 finished with value: -34.9852180480957 and parameters: {'num_layers': 38}. Best is trial 2 with value: -37.61505126953125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [01:28<00:00, 22.41it/s]\n",
      "  0%|          | 0/1992 [01:28<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting val epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [01:08<00:00, 29.25it/s]\n",
      "  0%|          | 0/1992 [01:08<?, ?it/s]\n",
      "[W 2023-06-29 23:07:52,065] Trial 4 failed with parameters: {'num_layers': 52} because of the following error: The value nan is not acceptable..\n",
      "[W 2023-06-29 23:07:52,074] Trial 4 failed with value tensor(nan, device='cuda:0', grad_fn=<DivBackward0>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [02:15<00:00, 14.69it/s]\n",
      "  0%|          | 0/1992 [02:15<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting val epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [00:38<00:00, 52.17it/s]\n",
      "  0%|          | 0/1992 [00:38<?, ?it/s]\n",
      "[I 2023-06-29 23:10:50,207] Trial 5 finished with value: -36.91230010986328 and parameters: {'num_layers': 29}. Best is trial 2 with value: -37.61505126953125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [04:06<00:00,  8.09it/s]\n",
      "  0%|          | 0/1992 [04:06<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting val epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [01:09<00:00, 28.68it/s]\n",
      "  0%|          | 0/1992 [01:09<?, ?it/s]\n",
      "[I 2023-06-29 23:16:08,666] Trial 6 finished with value: -35.582237243652344 and parameters: {'num_layers': 61}. Best is trial 2 with value: -37.61505126953125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [03:55<00:00,  8.47it/s]\n",
      "  0%|          | 0/1992 [03:55<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting val epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [01:03<00:00, 31.30it/s]\n",
      "  0%|          | 0/1992 [01:03<?, ?it/s]\n",
      "[I 2023-06-29 23:21:12,648] Trial 7 finished with value: -39.44623565673828 and parameters: {'num_layers': 57}. Best is trial 7 with value: -39.44623565673828.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [02:52<00:00, 11.57it/s]\n",
      "  0%|          | 0/1992 [02:52<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting val epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [00:43<00:00, 45.36it/s]\n",
      "  0%|          | 0/1992 [00:43<?, ?it/s]\n",
      "[I 2023-06-29 23:24:53,258] Trial 8 finished with value: -40.07331085205078 and parameters: {'num_layers': 39}. Best is trial 8 with value: -40.07331085205078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [03:39<00:00,  9.07it/s]\n",
      "  0%|          | 0/1992 [03:39<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting val epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [01:00<00:00, 32.91it/s]\n",
      "  0%|          | 0/1992 [01:00<?, ?it/s]\n",
      "[I 2023-06-29 23:29:36,655] Trial 9 finished with value: -42.10033416748047 and parameters: {'num_layers': 55}. Best is trial 9 with value: -42.10033416748047.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [01:32<00:00, 21.50it/s]\n",
      "  0%|          | 0/1992 [01:32<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting val epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [01:06<00:00, 29.81it/s]\n",
      "  0%|          | 0/1992 [01:06<?, ?it/s]\n",
      "/hpc/group/vossenlab/rck32/miniconda3/envs/venv/lib/python3.11/site-packages/optuna/pruners/_percentile.py:20: RuntimeWarning: All-NaN slice encountered\n",
      "  return np.nanmin(values)\n",
      "[I 2023-06-29 23:32:20,535] Trial 10 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [01:16<00:00, 26.02it/s]\n",
      "  0%|          | 0/1992 [01:16<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting val epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [00:57<00:00, 34.89it/s]\n",
      "  0%|          | 0/1992 [00:57<?, ?it/s]\n",
      "[I 2023-06-29 23:34:39,256] Trial 11 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [02:46<00:00, 11.97it/s]\n",
      "  0%|          | 0/1992 [02:46<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting val epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [00:59<00:00, 33.44it/s]\n",
      "  0%|          | 0/1992 [00:59<?, ?it/s]\n",
      "[I 2023-06-29 23:38:29,347] Trial 12 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [02:32<00:00, 13.04it/s]\n",
      "  0%|          | 0/1992 [02:32<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting val epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [00:43<00:00, 46.24it/s]\n",
      "  0%|          | 0/1992 [00:43<?, ?it/s]\n",
      "[I 2023-06-29 23:41:49,463] Trial 13 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [02:47<00:00, 11.89it/s]\n",
      "  0%|          | 0/1992 [02:47<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting val epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [00:38<00:00, 51.53it/s]\n",
      "  0%|          | 0/1992 [00:38<?, ?it/s]\n",
      "[I 2023-06-29 23:45:18,967] Trial 14 finished with value: -39.59315490722656 and parameters: {'num_layers': 40}. Best is trial 9 with value: -42.10033416748047.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [02:31<00:00, 13.11it/s]\n",
      "  0%|          | 0/1992 [02:31<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting val epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [00:44<00:00, 44.59it/s]\n",
      "  0%|          | 0/1992 [00:44<?, ?it/s]\n",
      "[I 2023-06-29 23:48:38,835] Trial 15 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [02:09<00:00, 15.37it/s]\n",
      "  0%|          | 0/1992 [02:09<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting val epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [00:32<00:00, 62.19it/s]\n",
      "  0%|          | 0/1992 [00:32<?, ?it/s]\n",
      "[I 2023-06-29 23:51:24,180] Trial 16 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [03:06<00:00, 10.66it/s]\n",
      "  0%|          | 0/1992 [03:06<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting val epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [00:41<00:00, 47.92it/s]\n",
      "  0%|          | 0/1992 [00:41<?, ?it/s]\n",
      "[I 2023-06-29 23:55:15,502] Trial 17 finished with value: -41.64117431640625 and parameters: {'num_layers': 43}. Best is trial 9 with value: -42.10033416748047.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  18\n",
      "  Number of pruned trials:  6\n",
      "  Number of complete trials:  10\n",
      "Best trial:\n",
      "  Value:  -42.10033416748047\n",
      "  Params: \n",
      "    num_layers: 55\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, timeout=3600)\n",
    "\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f56528-6523-4c90-b9b8-986852a9e936",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
