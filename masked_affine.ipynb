{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e889b5c3-6043-422b-994a-63436ed26189",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1514798/3111489797.py:13: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('svg', 'pdf') # For export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import normflows as nf\n",
    "from normflows import flows\n",
    "## Standard libraries\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import numpy as np \n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "from matplotlib.colors import to_rgb\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as tdata\n",
    "import torch.optim as optim\n",
    "\n",
    "import dgl #NOTE: for dgl.batch and dgl.unbatch\n",
    "from dgl import save_graphs, load_graphs\n",
    "from dgl.data import DGLDataset\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from dgl.data.utils import save_info, load_info, Subset\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Fetching the device that will be used throughout this notebook\n",
    "device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda:0\")\n",
    "print(\"Using device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2c2e4f0-72ff-4a37-a9d5-73ec9e8ac6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom imports\n",
    "from utils import load_graph_dataset, train, evaluate, GraphDataset, get_graph_dataset_info\n",
    "from models import GIN, HeteroGIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a02ccf8-30b1-472e-9a36-29b2d39da96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import default_rng\n",
    "rng = default_rng()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a973c3d3-3048-4397-92ff-f70e26c316be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''                                              '''\n",
    "'''     SETTING UP LATENT SPACE REPRESENTATION   '''\n",
    "'''                                              '''\n",
    "\n",
    "# Data and MC both have the same prefix\n",
    "prefix = \"/hpc/group/vossenlab/mfm45/.dgl/\"\n",
    "\n",
    "# MC inside Lambda_train_matched_jobs_outbending_cache_bg50nA_7_28_22__pT_phi_theta_beta_chi2_pid_status__Normalized\n",
    "MCdataset = \"Lambda_train_matched_jobs_outbending_cache_bg50nA_7_28_22__pT_phi_theta_beta_chi2_pid_status__Normalized\"\n",
    "\n",
    "# Data inside data_jobs_rga_fall2018_7_28_22__pT_phi_theta_beta_chi2_pid_status__Normalized\n",
    "DATAdataset = \"data_jobs_rga_fall2018_7_28_22__pT_phi_theta_beta_chi2_pid_status__Normalized\"\n",
    "\n",
    "max_events = 1e5\n",
    "split = 0.1\n",
    "nlayers = 2\n",
    "nmlp = 3\n",
    "hdim = 64\n",
    "nclasses, nfeatures, nfeatures_edge = get_graph_dataset_info(dataset=dataset, prefix=prefix)\n",
    "dropout = 0.8\n",
    "learn_eps = False\n",
    "batch = 256\n",
    "indices = None\n",
    "nworkers = 0\n",
    "npooling = \"max\"\n",
    "gpooling = \"max\"\n",
    "torch.manual_seed(0)\n",
    "\n",
    "#select model\n",
    "extractor = GIN(nlayers, nmlp, nfeatures,\n",
    "            hdim, nclasses, dropout, learn_eps, npooling, gpooling).to(device)\n",
    "extractor.load_state_dict(torch.load(\"logs/model_weights\",map_location=device))\n",
    "#select training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "00dd264e-a4cf-4009-afb0-48794c3302fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 0.8\n",
    "max_events = 140000\n",
    "test_range = range(int(split*max_events),max_events)\n",
    "test_dataset = GraphDataset(prefix+dataset)\n",
    "test_dataset.load()\n",
    "# test_dataset = Subset(test_dataset,range(int(min(len(test_dataset),max_events)*split)))\n",
    "test_dataset = Subset(test_dataset,test_range)\n",
    "test_bg = dgl.batch(test_dataset.dataset.graphs[test_dataset.indices.start:test_dataset.indices.stop])\n",
    "test_bg = test_bg.to(device)\n",
    "#grab latent space representation of graphs\n",
    "test_latent_repr = extractor.get_latent_repr(test_bg).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "75630610-7041-41a9-b57a-00ae09b641f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_range = range(0, int(split*max_events))\n",
    "train_dataset = GraphDataset(prefix+dataset)\n",
    "train_dataset.load()\n",
    "# train_dataset = Subset(train_dataset, range(int(min(len(test_dataset),max_events)*split),int(min(len(test_dataset),max_events))))\n",
    "train_dataset = Subset(train_dataset, train_range)\n",
    "train_dgl = dgl.batch(train_dataset.dataset.graphs[train_dataset.indices.start:train_dataset.indices.stop])\n",
    "train_dgl = train_dgl.to(device)\n",
    "#grab latentspace\n",
    "train_latent_repr = extractor.get_latent_repr(train_dgl).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fcf12578-76ee-4047-bc39-ec8cf03cc99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new dims for training\n",
    "train_num_events = train_latent_repr.size()[0]\n",
    "train_latent_size = train_latent_repr.size()[1]\n",
    "\n",
    "#calculate new dimensions for square version of latent space\n",
    "test_num_events = test_latent_repr.size()[0]\n",
    "test_latent_size = test_latent_repr.size()[1]\n",
    "\n",
    "assert(train_latent_size == test_latent_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5cb4cdf7-e316-447a-9567-841f446544eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Latent_data:\n",
    "    def __init__(self, in_tensor):\n",
    "        self.data = in_tensor\n",
    "        self.num_events = in_tensor.size()[0]\n",
    "        self.latent_size = in_tensor.size()[1]\n",
    "    def set_batch_size(self,batch_size):\n",
    "        self.batch_size = batch_size\n",
    "    def sample(self,iteration = 0, random = False):\n",
    "        if(random):\n",
    "            return self.sample_random()\n",
    "        else:\n",
    "            return self.sample_fixed(iteration)\n",
    "    def sample_fixed(self,iteration):\n",
    "        #0 index iterations - the \"first\" iteration is with iteration = 0\n",
    "        # Calculate the first index we want to take from training data (rest of data is directly after)\n",
    "        begin = iteration * self.batch_size\n",
    "        # initialize\n",
    "        samples = torch.zeros(self.batch_size, self.latent_size)\n",
    "        #loop over consecutive tensors, save to return tensor\n",
    "        for i in range(self.batch_size):\n",
    "            samples[i] = self.data[begin + i]\n",
    "        return samples\n",
    "    def sample_random(self):\n",
    "        indices = rng.integers(low=0, high=self.num_events, size=self.batch_size)\n",
    "        samples = torch.zeros(self.batch_size,self.latent_size)\n",
    "        for index in range(len(indices)):\n",
    "            samples[index] = self.data[indices[index]]\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1a4504dd-5bf9-4a68-bb64-46623b8d8972",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Trying different model from image.ipynb\n",
    "'''\n",
    "def get_masked_affine(num_layers = 32):\n",
    "    #mask\n",
    "    b = torch.ones(71)\n",
    "    for i in range(b.size()[0]):\n",
    "        if i % 2 == 0:\n",
    "            b[i] = 0\n",
    "    masked_affine_flows = []\n",
    "    for i in range(num_layers):\n",
    "        s = nf.nets.MLP([71, 142, 142, 71])\n",
    "        t = nf.nets.MLP([71, 142, 142, 71])\n",
    "        if i % 2 == 0:\n",
    "            masked_affine_flows += [nf.flows.MaskedAffineFlow(b, t, s)]\n",
    "        else:\n",
    "            masked_affine_flows += [nf.flows.MaskedAffineFlow(1 - b, t, s)]\n",
    "    return masked_affine_flows\n",
    "masked_affine_flows_train = get_masked_affine()\n",
    "distribution = nf.distributions.DiagGaussian(train_latent_size, trainable = False)\n",
    "masked_affine_model = nf.NormalizingFlow(q0=distribution, flows=masked_affine_flows_train)\n",
    "model = masked_affine_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c9d5389e-4dd8-4376-9909-1a1085b36a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set training info\n",
    "max_iter = int(np.floor((0.8 * 139000) / 500))\n",
    "num_samples = 500\n",
    "show_iter = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6645e53f-4f6c-45a2-a2ae-c7b95e8a6a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = Latent_data(train_latent_repr)\n",
    "training_data.set_batch_size(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "237f552d-6439-40e2-b0ca-3668fd24ae3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [00:16<00:00, 13.78it/s]\n",
      "  0%|          | 0/222 [00:16<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "model.train()\n",
    "loss_hist = np.array([])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-5)\n",
    "with tqdm(total=max_iter, position=0, leave=True) as pbar:\n",
    "    for it in tqdm(range(max_iter), position = 0, leave=True):\n",
    "        optimizer.zero_grad()\n",
    "        #randomly sample the latent space\n",
    "        samples = training_data.sample(iteration = it)\n",
    "        samples = samples.to(device)\n",
    "        loss = model.forward_kld(samples)\n",
    "        # Do backprop and optimizer step\n",
    "        if ~(torch.isnan(loss) | torch.isinf(loss)):\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # Log loss\n",
    "        if~(torch.isnan(loss)):\n",
    "            loss_hist = np.append(loss_hist, loss.to('cpu').data.numpy())\n",
    "\n",
    "# Plot loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "06836d1d-55be-47da-aeff-9b982302ef57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/pdf": "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",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"598.4875pt\" height=\"585.478125pt\" viewBox=\"0 0 598.4875 585.478125\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2023-06-20T11:15:55.696889</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.1, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 585.478125 \n",
       "L 598.4875 585.478125 \n",
       "L 598.4875 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 33.2875 561.6 \n",
       "L 591.2875 561.6 \n",
       "L 591.2875 7.2 \n",
       "L 33.2875 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"md4ac8e4cd9\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#md4ac8e4cd9\" x=\"58.651136\" y=\"561.6\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(55.469886 576.198438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#md4ac8e4cd9\" x=\"173.418722\" y=\"561.6\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 50 -->\n",
       "      <g transform=\"translate(167.056222 576.198438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#md4ac8e4cd9\" x=\"288.186307\" y=\"561.6\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 100 -->\n",
       "      <g transform=\"translate(278.642557 576.198438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#md4ac8e4cd9\" x=\"402.953892\" y=\"561.6\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 150 -->\n",
       "      <g transform=\"translate(393.410142 576.198438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#md4ac8e4cd9\" x=\"517.721478\" y=\"561.6\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 200 -->\n",
       "      <g transform=\"translate(508.177728 576.198438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <defs>\n",
       "       <path id=\"m251d3d4cae\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m251d3d4cae\" x=\"33.2875\" y=\"508.752957\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(19.925 512.552175) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m251d3d4cae\" x=\"33.2875\" y=\"390.098329\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 50 -->\n",
       "      <g transform=\"translate(13.5625 393.897548) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m251d3d4cae\" x=\"33.2875\" y=\"271.443702\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 100 -->\n",
       "      <g transform=\"translate(7.2 275.242921) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m251d3d4cae\" x=\"33.2875\" y=\"152.789075\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 150 -->\n",
       "      <g transform=\"translate(7.2 156.588294) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m251d3d4cae\" x=\"33.2875\" y=\"34.134448\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 200 -->\n",
       "      <g transform=\"translate(7.2 37.933666) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_11\">\n",
       "    <path d=\"M 58.651136 32.4 \n",
       "L 60.946488 212.416827 \n",
       "L 63.24184 243.34472 \n",
       "L 65.537191 255.015207 \n",
       "L 67.832543 264.526009 \n",
       "L 70.127895 268.729507 \n",
       "L 74.718598 284.423761 \n",
       "L 77.01395 290.116181 \n",
       "L 79.309302 296.707039 \n",
       "L 81.604653 304.638971 \n",
       "L 88.490709 322.834304 \n",
       "L 90.78606 332.054824 \n",
       "L 93.081412 338.775967 \n",
       "L 95.376764 347.308776 \n",
       "L 97.672115 350.743434 \n",
       "L 99.967467 357.808885 \n",
       "L 102.262819 367.243454 \n",
       "L 104.558171 373.439988 \n",
       "L 109.148874 384.677941 \n",
       "L 111.444226 390.65732 \n",
       "L 113.739577 396.051094 \n",
       "L 116.034929 399.515445 \n",
       "L 118.330281 403.930648 \n",
       "L 120.625632 406.984815 \n",
       "L 122.920984 413.46094 \n",
       "L 125.216336 413.565018 \n",
       "L 127.511688 418.590839 \n",
       "L 129.807039 421.954922 \n",
       "L 132.102391 423.006476 \n",
       "L 134.397743 425.381687 \n",
       "L 136.693094 431.317822 \n",
       "L 138.988446 435.298222 \n",
       "L 141.283798 433.231439 \n",
       "L 143.57915 437.794729 \n",
       "L 145.874501 440.847951 \n",
       "L 148.169853 444.62019 \n",
       "L 150.465205 441.054844 \n",
       "L 152.760556 444.262467 \n",
       "L 155.055908 444.02713 \n",
       "L 157.35126 450.484253 \n",
       "L 159.646611 451.283985 \n",
       "L 161.941963 457.502137 \n",
       "L 164.237315 451.056814 \n",
       "L 166.532667 454.165342 \n",
       "L 168.828018 459.659193 \n",
       "L 171.12337 457.128345 \n",
       "L 173.418722 461.247997 \n",
       "L 175.714073 460.597557 \n",
       "L 178.009425 465.001122 \n",
       "L 180.304777 466.622657 \n",
       "L 182.600129 461.743946 \n",
       "L 184.89548 468.503553 \n",
       "L 187.190832 469.65264 \n",
       "L 189.486184 467.071445 \n",
       "L 191.781535 471.040994 \n",
       "L 194.076887 473.475402 \n",
       "L 196.372239 474.885847 \n",
       "L 200.962942 479.56115 \n",
       "L 203.258294 475.847245 \n",
       "L 205.553646 446.935247 \n",
       "L 207.848997 451.335137 \n",
       "L 210.144349 452.487903 \n",
       "L 212.439701 456.754294 \n",
       "L 214.735052 460.44789 \n",
       "L 217.030404 468.190735 \n",
       "L 219.325756 473.41604 \n",
       "L 221.621108 476.196892 \n",
       "L 223.916459 470.967722 \n",
       "L 226.211811 470.650466 \n",
       "L 228.507163 474.029095 \n",
       "L 230.802514 474.201971 \n",
       "L 233.097866 472.624364 \n",
       "L 235.393218 479.043455 \n",
       "L 237.68857 476.327033 \n",
       "L 239.983921 480.787209 \n",
       "L 242.279273 478.652737 \n",
       "L 244.574625 483.7271 \n",
       "L 246.869976 478.789945 \n",
       "L 249.165328 484.781888 \n",
       "L 251.46068 484.806676 \n",
       "L 253.756031 484.503913 \n",
       "L 256.051383 486.071104 \n",
       "L 258.346735 488.018198 \n",
       "L 260.642087 488.665733 \n",
       "L 262.937438 490.342787 \n",
       "L 265.23279 493.730838 \n",
       "L 267.528142 491.952017 \n",
       "L 269.823493 495.110943 \n",
       "L 272.118845 497.666574 \n",
       "L 274.414197 495.537224 \n",
       "L 276.709549 495.306348 \n",
       "L 279.0049 501.531133 \n",
       "L 281.300252 501.306397 \n",
       "L 283.595604 499.506165 \n",
       "L 285.890955 493.188528 \n",
       "L 288.186307 496.920647 \n",
       "L 290.481659 497.88724 \n",
       "L 292.77701 501.658652 \n",
       "L 295.072362 501.616201 \n",
       "L 297.367714 504.179217 \n",
       "L 299.663066 502.523842 \n",
       "L 301.958417 498.344615 \n",
       "L 304.253769 497.944149 \n",
       "L 306.549121 501.620885 \n",
       "L 308.844472 506.399939 \n",
       "L 311.139824 498.370303 \n",
       "L 313.435176 492.902855 \n",
       "L 315.730528 496.517194 \n",
       "L 318.025879 499.148953 \n",
       "L 320.321231 500.665465 \n",
       "L 322.616583 500.141643 \n",
       "L 324.911934 505.458542 \n",
       "L 327.207286 507.18979 \n",
       "L 329.502638 506.044648 \n",
       "L 331.79799 508.083879 \n",
       "L 334.093341 506.401424 \n",
       "L 336.388693 507.449048 \n",
       "L 338.684045 507.145574 \n",
       "L 340.979396 507.509653 \n",
       "L 343.274748 510.666807 \n",
       "L 345.5701 512.033246 \n",
       "L 347.865451 507.609656 \n",
       "L 350.160803 509.026655 \n",
       "L 352.456155 511.582707 \n",
       "L 354.751507 517.992521 \n",
       "L 357.046858 511.992101 \n",
       "L 359.34221 513.511492 \n",
       "L 361.637562 512.623138 \n",
       "L 366.228265 518.731269 \n",
       "L 368.523617 522.30937 \n",
       "L 370.818969 514.493066 \n",
       "L 373.11432 522.89058 \n",
       "L 375.409672 517.755582 \n",
       "L 377.705024 520.669206 \n",
       "L 380.000375 517.164352 \n",
       "L 382.295727 521.483918 \n",
       "L 384.591079 518.897963 \n",
       "L 386.88643 514.990729 \n",
       "L 389.181782 520.136469 \n",
       "L 391.477134 517.509148 \n",
       "L 393.772486 523.868943 \n",
       "L 396.067837 524.728886 \n",
       "L 398.363189 520.826429 \n",
       "L 400.658541 519.841643 \n",
       "L 402.953892 512.767765 \n",
       "L 405.249244 520.996444 \n",
       "L 407.544596 515.910743 \n",
       "L 409.839948 512.151991 \n",
       "L 412.135299 515.194978 \n",
       "L 414.430651 519.13151 \n",
       "L 416.726003 516.390388 \n",
       "L 419.021354 496.787828 \n",
       "L 421.316706 489.015008 \n",
       "L 423.612058 493.173748 \n",
       "L 425.90741 506.101304 \n",
       "L 428.202761 502.897766 \n",
       "L 430.498113 502.554598 \n",
       "L 432.793465 507.208225 \n",
       "L 435.088816 505.661228 \n",
       "L 437.384168 510.162696 \n",
       "L 439.67952 507.961033 \n",
       "L 441.974871 511.484494 \n",
       "L 444.270223 515.748036 \n",
       "L 446.565575 516.140228 \n",
       "L 448.860927 518.458498 \n",
       "L 453.45163 510.639656 \n",
       "L 455.746982 512.578264 \n",
       "L 458.042333 516.882196 \n",
       "L 460.337685 517.052906 \n",
       "L 462.633037 515.999399 \n",
       "L 464.928389 516.757311 \n",
       "L 467.22374 517.290175 \n",
       "L 469.519092 514.875005 \n",
       "L 471.814444 516.476193 \n",
       "L 474.109795 518.775913 \n",
       "L 476.405147 520.146605 \n",
       "L 478.700499 523.143464 \n",
       "L 480.99585 519.66997 \n",
       "L 483.291202 521.219916 \n",
       "L 485.586554 523.424176 \n",
       "L 487.881906 523.17582 \n",
       "L 490.177257 521.76335 \n",
       "L 492.472609 524.799003 \n",
       "L 494.767961 526.280494 \n",
       "L 497.063312 521.816585 \n",
       "L 499.358664 520.188934 \n",
       "L 501.654016 513.350882 \n",
       "L 503.949368 525.65822 \n",
       "L 506.244719 516.602779 \n",
       "L 508.540071 517.259173 \n",
       "L 510.835423 514.198 \n",
       "L 513.130774 522.637776 \n",
       "L 515.426126 515.386207 \n",
       "L 517.721478 509.925091 \n",
       "L 520.016829 507.841114 \n",
       "L 522.312181 508.886007 \n",
       "L 524.607533 518.917761 \n",
       "L 526.902885 520.2519 \n",
       "L 529.198236 517.423159 \n",
       "L 531.493588 520.011077 \n",
       "L 533.78894 522.379688 \n",
       "L 538.379643 525.026074 \n",
       "L 540.674995 529.407645 \n",
       "L 542.970347 523.724171 \n",
       "L 545.265698 526.087451 \n",
       "L 547.56105 528.012476 \n",
       "L 549.856402 526.698774 \n",
       "L 552.151753 529.229136 \n",
       "L 554.447105 534.35648 \n",
       "L 556.742457 532.414089 \n",
       "L 559.037809 531.041088 \n",
       "L 561.33316 531.637488 \n",
       "L 563.628512 536.4 \n",
       "L 565.923864 535.438882 \n",
       "L 565.923864 535.438882 \n",
       "\" clip-path=\"url(#pffff0bc547)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 2; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 33.2875 561.6 \n",
       "L 33.2875 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 591.2875 561.6 \n",
       "L 591.2875 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 33.2875 561.6 \n",
       "L 591.2875 561.6 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 33.2875 7.2 \n",
       "L 591.2875 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 532.971875 29.878125 \n",
       "L 584.2875 29.878125 \n",
       "Q 586.2875 29.878125 586.2875 27.878125 \n",
       "L 586.2875 14.2 \n",
       "Q 586.2875 12.2 584.2875 12.2 \n",
       "L 532.971875 12.2 \n",
       "Q 530.971875 12.2 530.971875 14.2 \n",
       "L 530.971875 27.878125 \n",
       "Q 530.971875 29.878125 532.971875 29.878125 \n",
       "z\n",
       "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_12\">\n",
       "     <path d=\"M 534.971875 20.298438 \n",
       "L 544.971875 20.298438 \n",
       "L 554.971875 20.298438 \n",
       "\" style=\"fill: none; stroke: #1f77b4; stroke-width: 2; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_11\">\n",
       "     <!-- loss -->\n",
       "     <g transform=\"translate(562.971875 23.798438) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"27.783203\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"88.964844\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"141.064453\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pffff0bc547\">\n",
       "   <rect x=\"33.2875\" y=\"7.2\" width=\"558\" height=\"554.4\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.plot(loss_hist, label='loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig.savefig(\"loss_masked_affine.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2ed9c541-ec86-4a6b-a931-acfbfb6334b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-11.650217056274414"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_hist.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ac22e071-3cb5-47bc-bfed-7aa1d898045e",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = Latent_data(test_latent_repr)\n",
    "testing_data.set_batch_size(num_samples)\n",
    "max_iter_test = int(np.floor((testing_data.num_events / num_samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8bcbba6b-73fb-4519-81c4-70986a3e10e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:01<00:00, 49.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss: -9.335673332214355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model.eval()\n",
    "num_samples = 500\n",
    "test_loss = 0\n",
    "new_loss = 0\n",
    "counted_batches = 0\n",
    "with torch.no_grad():\n",
    "    for it in tqdm(range(max_iter_test), position = 0, leave=True):\n",
    "        test_samples = testing_data.sample(iteration = it)\n",
    "        test_samples = test_samples.to(device)\n",
    "        new_loss = model.forward_kld(test_samples)\n",
    "        if(not math.isnan(new_loss)):\n",
    "#             print(f\"new_loss: {new_loss}\")\n",
    "            test_loss += new_loss\n",
    "            counted_batches += 1\n",
    "    print(f\"average loss: {test_loss/counted_batches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "09fdd7b9-47bf-4181-aa4a-479993d6b5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#avg loss on trained gauss: -7.84237003326416"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9cb3f616-31fc-4b86-a065-1481af072410",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_latent = torch.zeros_like(test_latent_repr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ba2d92c5-9c59-4753-b597-ba926ab2eb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_batches = torch.empty(max_iter_test,num_samples,testing_data.latent_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6edd25aa-79dd-4417-9831-d8aeab3db717",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:00<00:00, 58.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# Closure Test - run inverse() then forward()\n",
    "\n",
    "'''\n",
    "Inverse run\n",
    "    -input: latent_repr\n",
    "    -output: gaussian version\n",
    "'''\n",
    "torch.manual_seed(42)\n",
    "model.eval()\n",
    "num_samples = 500\n",
    "counted_batches = 0\n",
    "with torch.no_grad():\n",
    "    for it in tqdm(range(max_iter_test), position = 0, leave=True):\n",
    "        test_samples = testing_data.sample(iteration = it)\n",
    "        test_samples = test_samples.to(device)\n",
    "        output_batches[it] = model.inverse(test_samples)\n",
    "        #for i in range(num_samples):\n",
    "        #    transformed_latent[it*num_samples + i] = output_batch[i]\n",
    "output_batches = output_batches.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b6294815-077e-417e-8c2c-7a385aeb2a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:01<00:00, 49.66it/s]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Forward run\n",
    "    -input: gauss version\n",
    "    -output: latent space\n",
    "'''\n",
    "final_output = torch.empty(output_batches.size()[1],output_batches.size()[2])\n",
    "transformed_latent = torch.zeros_like(test_latent_repr)\n",
    "model.eval()\n",
    "counted_batches = 0\n",
    "with torch.no_grad():\n",
    "    for it in tqdm(range(max_iter_test), position = 0, leave=True):\n",
    "        final_output = model.forward(output_batches[it])\n",
    "        for i in range(num_samples):\n",
    "            transformed_latent[it*num_samples + i] = final_output[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9ad8c6a7-a3ab-4328-8cbb-707c3ae0b0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max difference: 8.58306884765625e-06\n",
      "average difference: 1.2198321996947925e-07\n"
     ]
    }
   ],
   "source": [
    "diff = transformed_latent - test_latent_repr\n",
    "print(f\"max difference: {diff.max()}\\naverage difference: {diff.sum() / np.prod(transformed_latent.size())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e9d74df2-36e7-4d28-9e6c-41e88a833a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average error: 1.0209369975200389e-05%\n"
     ]
    }
   ],
   "source": [
    "print(f\"average error: {100*(diff.sum() / np.prod(transformed_latent.size()))/(transformed_latent.sum() / np.prod(transformed_latent.size()))}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa38fd6f-19b5-4e45-9c70-4a6697c82bbe",
   "metadata": {},
   "source": [
    "Max diff: tensor(1.2398e-05)\n",
    "\n",
    "average diff: tensor(1.2707e-07) | tensor(1.3718e-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbadb2c-4672-4f16-9383-6b4c6d89d632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
